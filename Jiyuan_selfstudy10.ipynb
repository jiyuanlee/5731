{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jiyuan-selfstudy10.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "RZ1RigWUbQUY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_data(data, prob):\n",
        "    \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
        "    results = [], []\n",
        "    for row in data:\n",
        "        results[0 if random.random() < prob else 1].append(row)\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cGfhysq1bQkB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_test_split(x, y, test_pct):\n",
        "  data = zip(x, y) # pair corresponding values\n",
        "  train, test = split_data(data, 1 - test_pct) # split the data set of pairs\n",
        "  x_train, y_train = zip(*train) # magical un-zip trick\n",
        "  x_test, y_test = zip(*test)\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3IwVbjnobQnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "e1bd71af-15b9-446f-a20d-a2f3dcc1caab"
      },
      "cell_type": "code",
      "source": [
        "model = SomeKindOfModel()\n",
        "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.33)\n",
        "model.train(x_train, y_train)\n",
        "performance = model.test(x_test, y_test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-dc14719325ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSomeKindOfModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SomeKindOfModel' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YqsK5yS7bMVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9f90b3a-d175-4fed-8473-76fc12558c88"
      },
      "cell_type": "code",
      "source": [
        "def accuracy(tp, fp, fn, tn):\n",
        "    correct = tp + tn\n",
        "    total = tp + fp + fn + tn\n",
        "    return correct / total\n",
        "\n",
        "print(accuracy(70, 4930, 13930, 981070)) # 0.98114"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.98114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c4PMHokXbVJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb1be417-5d4d-42c8-c7e6-7945cb9f682e"
      },
      "cell_type": "code",
      "source": [
        "def precision(tp, fp, fn, tn):\n",
        "  return tp / (tp + fp)\n",
        "print(precision(70, 4930, 13930, 981070))# 0.014"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ocaeJsj2bib6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2630a976-cbcf-4fa9-8f2d-af1a372af657"
      },
      "cell_type": "code",
      "source": [
        "def recall(tp, fp, fn, tn):\n",
        "  return tp / (tp + fn)\n",
        "print(recall(70, 4930, 13930, 981070)) # 0.005"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gG-O0C5Qbl-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def f1_score(tp, fp, fn, tn):\n",
        "  p = precision(tp, fp, fn, tn)\n",
        "  r = recall(tp, fp, fn, tn)\n",
        "  return 2 * p * r / (p + r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S141b-jHbvmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6dAFeX2rmZD7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "chapter 13"
      ]
    },
    {
      "metadata": {
        "id": "v9ZxYbWamhez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize(message):   \n",
        "  message = message.lower()                       # convert to lowercase    \n",
        "  all_words = re.findall(\"[a-z0-9']+\", message)   # extract the words    \n",
        "  return set(all_words)                           # remove duplicates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HcIK9Bt0mp00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_words(training_set):    \n",
        "  \"\"\"training set consists of pairs (message, is_spam)\"\"\"    \n",
        "  counts = defaultdict(lambda: [0, 0])    \n",
        "  for message, is_spam in training_set:        \n",
        "    for word in tokenize(message):            \n",
        "      counts[word][0 if is_spam else 1] += 1    \n",
        "      return counts "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sv-R0bkGm1wR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):    \n",
        "  \"\"\"turn the word_counts into a list of triplets    w, p(w | spam) and p(w | ~spam)\"\"\"    \n",
        "  return [(w,             (spam + k) / (total_spams + 2 * k),(non_spam + k) / (total_non_spams + 2 * k))             \n",
        "          for w, (spam, non_spam) in counts.iteritems()] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BAW0RODGnFlq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def spam_probability(word_probs, message):   \n",
        "  message_words = tokenize(message)    \n",
        "  log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
        "    # iterate through each word in our vocabulary    \n",
        "  for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
        "        # if *word* appears in the message,        # add the log probability of seeing it        \n",
        "      if word in message_words:\n",
        "          log_prob_if_spam += math.log(prob_if_spam)            \n",
        "          log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
        "   # if *word* doesn't appear in the message        # add the log probability of _not_ seeing it        # which is log(1 - probability of seeing it)        \n",
        "      else:            \n",
        "          log_prob_if_spam += math.log(1.0 - prob_if_spam)            \n",
        "          log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
        "  prob_if_spam = math.exp(log_prob_if_spam)   \n",
        "  prob_if_not_spam = math.exp(log_prob_if_not_spam)    \n",
        "  return prob_if_spam / (prob_if_spam + prob_if_not_spam) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ib1vdlcgnM70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, k=0.5):        \n",
        "      self.k = k        \n",
        "      self.word_probs = []\n",
        "    def train(self, training_set):\n",
        "        # count spam and non-spam messages        \n",
        "        num_spams = len([is_spam                        \n",
        "                         for message, is_spam in training_set                         \n",
        "                         if is_spam])       \n",
        "        num_non_spams = len(training_set) - num_spams\n",
        "        # run training data through our \"pipeline\"        \n",
        "        word_counts = count_words(training_set)        \n",
        "        self.word_probs = word_probabilities(word_counts,                                             \n",
        "                                             num_spams,                                             \n",
        "                                             num_non_spams,                                             \n",
        "                                             self.k)\n",
        "    def classify(self, message):        \n",
        "      return spam_probability(self.word_probs, message) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1SgS9G4fn5S6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob, re\n",
        "# modify the path with wherever you've put the files path = r\"C:\\spam\\*\\*\"\n",
        "data = []\n",
        "# glob.glob returns every filename that matches the wildcarded path \n",
        "for fn in glob.glob('path'):    \n",
        "    is_spam = \"ham\" not in fn\n",
        "    with open(fn,'r') as file:        \n",
        "      for line in file:            \n",
        "        if line.startswith(\"Subject:\"):                # remove the leading \"Subject: \" and keep what's left                \n",
        "          subject = re.sub(r\"^Subject: \", \"\", line).strip()                \n",
        "          data.append((subject, is_spam)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cdzrDkraos_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "5e5df92e-69c4-4835-9e0e-a96380334f65"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "random.seed(0)      # just so you get the same answers as me \n",
        "train_data, test_data = split_data(data, 0.75)\n",
        "classifier = NaiveBayesClassifier() \n",
        "classifier.train(train_data) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d7f2dd134d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-14746c2e63dc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_set)\u001b[0m\n\u001b[1;32m     14\u001b[0m                                              \u001b[0mnum_spams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                              \u001b[0mnum_non_spams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                              self.k)\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mspam_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-984cf506d2b2>\u001b[0m in \u001b[0;36mword_probabilities\u001b[0;34m(counts, total_spams, total_non_spams, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;34m\"\"\"turn the word_counts into a list of triplets    w, p(w | spam) and p(w | ~spam)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   return [(w,             (spam + k) / (total_spams + 2 * k),(non_spam + k) / (total_non_spams + 2 * k))             \n\u001b[0;32m----> 4\u001b[0;31m           for w, (spam, non_spam) in counts.iteritems()] \n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'iteritems'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5577EvcOpYRS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "# triplets (subject, actual is_spam, predicted spam probability) \n",
        "classified = [(subject, is_spam, classifier.classify(subject))              \n",
        "              for subject, is_spam in test_data]\n",
        "# assume that spam_probability > 0.5 corresponds to spam prediction \n",
        "# and count the combinations of (actual is_spam, predicted is_spam) \n",
        "counts = Counter((is_spam, spam_probability > 0.5)                 \n",
        "                 for _, is_spam, spam_probability in classified) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L9l-poD7qCR4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "66c669dd-8fe3-4fad-80ab-204dc0f9cbf0"
      },
      "cell_type": "code",
      "source": [
        "# sort by spam_probability from smallest to largest \n",
        "classified.sort(key=lambda row: row[2])\n",
        "# the highest predicted spam probabilities among the non-spams\n",
        "spammiest_hams = next(lambda row: not row[1], classified)[-5:]\n",
        "# the lowest predicted spam probabilities among the actual spams \n",
        "hammiest_spams = next(lambda row: row[1], classified)[:5] \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d72a3ec4cbbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# the highest predicted spam probabilities among the non-spams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspammiest_hams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# the lowest predicted spam probabilities among the actual spams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhammiest_spams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'function' object is not an iterator"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rPtpqTsoqQ7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def p_spam_given_word(word_prob):    \n",
        "    \"\"\"uses bayes's theorem to compute p(spam | message contains word)\"\"\"\n",
        "    # word_prob is one of the triplets produced by word_probabilities    \n",
        "    word, prob_if_spam, prob_if_not_spam = word_prob    \n",
        "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)\n",
        "words = sorted(classifier.word_probs, key=p_spam_given_word)\n",
        "spammiest_words = words[-5:] \n",
        "hammiest_words = words[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NbRMS8pHqwbK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " def drop_final_s(word):    \n",
        "    return re.sub(\"s$\", \"\", word)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "55hwLyf6q3Z2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "igJIylKmq9fb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "chapter 17"
      ]
    },
    {
      "metadata": {
        "id": "H5gZj5EYq_CW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def entropy(class_probabilities):    \n",
        "    \"\"\"given a list of class probabilities, compute the entropy\"\"\"    \n",
        "    return sum(-p * math.log(p, 2)               \n",
        "               for p in class_probabilities               \n",
        "               if p)                         # ignore zero probabilities "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDWKaP_HruV0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def class_probabilities(labels):    \n",
        "  total_count = len(labels)    \n",
        "  return [count / total_count            \n",
        "          for count in Counter(labels).values()]\n",
        "def data_entropy(labeled_data):    \n",
        "  labels = [label for _, label in labeled_data]    \n",
        "  probabilities = class_probabilities(labels)    \n",
        "  return entropy(probabilities) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xu-Lo2ddr7VX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_entropy(subsets):    \n",
        "    \"\"\"find the entropy from this partition of data into subsets    \n",
        "    subsets is a list of lists of labeled data\"\"\"\n",
        "    total_count = sum(len(subset) for subset in subsets)\n",
        "    return sum( data_entropy(subset) * len(subset) / total_count                \n",
        "               for subset in subsets )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AmI_79j0sEaQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = [({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'no'},    False),\n",
        "          ({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'yes'},   False),\n",
        "          ({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'no'},      True),\n",
        "          ({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'no'},   True),\n",
        "          ({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'no'},       True),\n",
        "          ({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'yes'},     False),\n",
        "          ({'level':'Mid', 'lang':'R', 'tweets':'yes', 'phd':'yes'},         True),\n",
        "          ({'level':'Senior', 'lang':'Python', 'tweets':'no', 'phd':'no'},  False),\n",
        "          ({'level':'Senior', 'lang':'R', 'tweets':'yes', 'phd':'no'},       True),\n",
        "          ({'level':'Junior', 'lang':'Python', 'tweets':'yes', 'phd':'no'},  True),\n",
        "          ({'level':'Senior', 'lang':'Python', 'tweets':'yes', 'phd':'yes'}, True),\n",
        "          ({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'yes'},     True),\n",
        "          ({'level':'Mid', 'lang':'Java', 'tweets':'yes', 'phd':'no'},       True),\n",
        "          ({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, False) \n",
        "         ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "92FR3IOHsRwT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_by(inputs, attribute):    \n",
        "    \"\"\"each input is a pair (attribute_dict, label).    \n",
        "    returns a dict : attribute_value -> inputs\"\"\"   \n",
        "    groups = defaultdict(list)    \n",
        "    for input in inputs:        \n",
        "      key = input[0][attribute]   # get the value of the specified attribute        \n",
        "      groups[key].append(input)   # then add this input to the correct list    \n",
        "    return groups "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IsuFxz_FsaSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_entropy_by(inputs, attribute):    \n",
        "    \"\"\"computes the entropy corresponding to the given partition\"\"\"    \n",
        "    partitions = partition_by(inputs, attribute)    \n",
        "    return partition_entropy(partitions.values()) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4zfMkyV_sfqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b46520c7-3367-4599-b54e-1eb5369c5087"
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "for key in ['level','lang','tweets','phd']:    \n",
        "  print(key, partition_entropy_by(inputs, key))\n",
        "# level 0.693536138896 \n",
        "# lang 0.860131712855 \n",
        "# tweets 0.788450457308 \n",
        "# phd 0.892158928262 "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "level 0.6935361388961919\n",
            "lang 0.8601317128547441\n",
            "tweets 0.7884504573082896\n",
            "phd 0.8921589282623617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V-MIhRWAsjyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4e71505d-4245-473c-ca40-7b403325b022"
      },
      "cell_type": "code",
      "source": [
        "senior_inputs = [(input, label)                 \n",
        "                 for input, label in inputs if input[\"level\"] == \"Senior\"]\n",
        "for key in ['lang', 'tweets', 'phd']:    \n",
        "  print(key, partition_entropy_by(senior_inputs, key))\n",
        "# lang 0.4 # tweets 0.0 # phd 0.950977500433"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lang 0.4\n",
            "tweets 0.0\n",
            "phd 0.9509775004326938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PgFDFxBdtFb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "64ec2243-5d07-4949-baf4-35ac9c033736"
      },
      "cell_type": "code",
      "source": [
        "('level', \n",
        " {'Junior': ('phd', {'no': True, 'yes': False}),  \n",
        "  'Mid': True,  \n",
        "  'Senior': ('tweets', {'no': False, 'yes': True})})"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('level',\n",
              " {'Junior': ('phd', {'no': True, 'yes': False}),\n",
              "  'Mid': True,\n",
              "  'Senior': ('tweets', {'no': False, 'yes': True})})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "S2o7hSzutfFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classify(tree, input):    \n",
        "    \"\"\"classify the input using the given decision tree\"\"\"\n",
        "    # if this is a leaf node, return its value    \n",
        "    if tree in [True, False]:        \n",
        "      return tree\n",
        "    # otherwise this tree consists of an attribute to split on    \n",
        "    # and a dictionary whose keys are values of that attribute    \n",
        "    # and whose values of are subtrees to consider next    \n",
        "    attribute, subtree_dict = tree\n",
        "    subtree_key = input.get(attribute)    # None if input is missing attribute\n",
        "    if subtree_key not in subtree_dict:   # if no subtree for key,        \n",
        "      subtree_key = None                # we'll use the None subtree\n",
        "    subtree = subtree_dict[subtree_key]   # choose the appropriate subtree    \n",
        "    return classify(subtree, input)       # and use it to classify the input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ewrDSt1Vtp-o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_tree_id3(inputs, split_candidates=None):\n",
        "    # if this is our first pass,    \n",
        "    # all keys of the first input are split candidates\n",
        "    if split_candidates is None:        \n",
        "      split_candidates = inputs[0][0].keys()\n",
        "    # count Trues and Falses in the inputs    \n",
        "    num_inputs = len(inputs)    \n",
        "    num_trues = len([label for item, label in inputs if label])    \n",
        "    num_falses = num_inputs - num_trues\n",
        "    if num_trues == 0: return False     # no Trues? return a \"False\" leaf    if num_falses == 0: return True     # no Falses? return a \"True\" leaf\n",
        "    if not split_candidates:            # if no split candidates left        \n",
        "      return num_trues >= num_falses  # return the majority leaf\n",
        "    # otherwise, split on the best attribute    \n",
        "    best_attribute = min(split_candidates,                         \n",
        "                         key=partial(partition_entropy_by, inputs))\n",
        "    partitions = partition_by(inputs, best_attribute)    \n",
        "    new_candidates = [a for a in split_candidates                      \n",
        "                      if a != best_attribute]\n",
        "    # recursively build the subtrees    \n",
        "    subtrees = { attribute_value : build_tree_id3(subset, new_candidates)                 \n",
        "                for attribute_value, subset in partitions.iteritems() }\n",
        "    subtrees[None] = num_trues > num_falses      # default case\n",
        "    return (best_attribute, subtrees) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5Fi6K5RuF_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "658ef17b-30e5-4e78-9142-460113bad44e"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "tree = build_tree_id3(inputs)\n",
        "classify(tree, {\"level\" : \"Junior\",                 \n",
        "                \"lang\" : \"Java\",                 \n",
        "                \"tweets\" : \"yes\",                \n",
        "                \"phd\" : \"no\"} )        # True\n",
        "classify(tree, {\"level\" : \"Junior\",                 \n",
        "                \"lang\" : \"Java\",                 \n",
        "                \"tweets\" : \"yes\",                 \n",
        "                \"phd\" : \"yes\"} )       # False "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c380e318ba0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_tree_id3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m classify(tree, {\"level\" : \"Junior\",                 \n\u001b[1;32m      4\u001b[0m                 \u001b[0;34m\"lang\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"Java\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;34m\"tweets\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-a8ae8c750537>\u001b[0m in \u001b[0;36mbuild_tree_id3\u001b[0;34m(inputs, split_candidates)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# otherwise, split on the best attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     best_attribute = min(split_candidates,                         \n\u001b[0;32m---> 15\u001b[0;31m                          key=partial(partition_entropy_by, inputs))\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mpartitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_attribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     new_candidates = [a for a in split_candidates                      \n",
            "\u001b[0;31mNameError\u001b[0m: name 'partial' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "85X3Xw-BuN5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "48a18600-48d9-44c0-8ce5-37714f905745"
      },
      "cell_type": "code",
      "source": [
        "classify(tree, { \"level\" : \"Intern\" } ) # True \n",
        "classify(tree, { \"level\" : \"Senior\" } ) # False"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-d29436f79a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"level\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"Intern\"\u001b[0m \u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"level\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"Senior\"\u001b[0m \u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-9a7603ed0795>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(tree, input)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# and a dictionary whose keys are values of that attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# and whose values of are subtrees to consider next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtree_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0msubtree_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# None if input is missing attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubtree_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubtree_dict\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# if no subtree for key,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not iterable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vkAsPlCsuejp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forest_classify(trees, input):    \n",
        "  votes = [classify(tree, input) for tree in trees]    \n",
        "  vote_counts = Counter(votes)    \n",
        "  return vote_counts.most_common(1)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0XrT7cKyut7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6cf3a0c8-e73e-4c16-c78e-afc160130043"
      },
      "cell_type": "code",
      "source": [
        "  # if there's already few enough split candidates, look at all of them    \n",
        "  if len(split_candidates) <= self.num_split_candidates:        \n",
        "    sampled_split_candidates = split_candidates    \n",
        "    # otherwise pick a random sample    \n",
        "  else:       \n",
        "    sampled_split_candidates = random.sample(split_candidates,                                                 \n",
        "                                             self.num_split_candidates)\n",
        "    # now choose the best attribute only from those candidates    \n",
        "  best_attribute = min(sampled_split_candidates,        \n",
        "                         key=partial(partition_entropy_by, inputs))\n",
        "  partitions = partition_by(inputs, best_attribute)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-394643cbb60b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_candidates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_split_candidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0msampled_split_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# otherwise pick a random sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   sampled_split_candidates = random.sample(split_candidates,                                                 \n",
            "\u001b[0;31mNameError\u001b[0m: name 'split_candidates' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "iT7D_WgLu-LF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tKfPl1yjvnCC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "NLTK chapter 6"
      ]
    },
    {
      "metadata": {
        "id": "10m79Hl6vmap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "482fb472-a0c8-49b4-8895-de0481f40c8d"
      },
      "cell_type": "code",
      "source": [
        ">>> def gender_features(word):\n",
        "...     return {'last_letter': word[-1]}\n",
        ">>> gender_features('Shrek')\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last_letter': 'k'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "9YOxJViVv6oi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "710c2ace-df50-4942-f8d0-9bba7e4eb4fb"
      },
      "cell_type": "code",
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download('names')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "YKShkErcwAow",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> from nltk.corpus import names\n",
        ">>> labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
        "... [(name, 'female') for name in names.words('female.txt')])\n",
        ">>> import random\n",
        ">>> random.shuffle(labeled_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YeAsyyyMwavP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        ">>> train_set, test_set = featuresets[500:], featuresets[:500]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "88BF6fHKwehH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39a73af9-a75f-4e6b-9b11-dd16ad209566"
      },
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Neo'))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'male'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "c1CPyOStwe_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc0608ea-6876-4ac6-c33e-d7f0da7a1a68"
      },
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Trinity'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'female'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "D0F9YaDIwgjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87c1520f-2f31-4d01-af09-831f9455c8fd"
      },
      "cell_type": "code",
      "source": [
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XNz8ysGGwi3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e4072d36-ebf0-401f-be4b-f05c28b4d3f5"
      },
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'a'            female : male   =     35.7 : 1.0\n",
            "             last_letter = 'k'              male : female =     30.8 : 1.0\n",
            "             last_letter = 'p'              male : female =     20.9 : 1.0\n",
            "             last_letter = 'f'              male : female =     15.3 : 1.0\n",
            "             last_letter = 'v'              male : female =     10.5 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HFjybMO8wmWt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> from nltk.classify import apply_features\n",
        ">>> train_set = apply_features(gender_features, labeled_names[500:])\n",
        ">>> test_set = apply_features(gender_features, labeled_names[:500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZIW4biBBwsww",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gender_features2(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dzxpk_r1wvbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "outputId": "995214f2-bcbc-4641-a0fa-a496c8576aae"
      },
      "cell_type": "code",
      "source": [
        " gender_features2('John')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'count(a)': 0,\n",
              " 'count(b)': 0,\n",
              " 'count(c)': 0,\n",
              " 'count(d)': 0,\n",
              " 'count(e)': 0,\n",
              " 'count(f)': 0,\n",
              " 'count(g)': 0,\n",
              " 'count(h)': 1,\n",
              " 'count(i)': 0,\n",
              " 'count(j)': 1,\n",
              " 'count(k)': 0,\n",
              " 'count(l)': 0,\n",
              " 'count(m)': 0,\n",
              " 'count(n)': 1,\n",
              " 'count(o)': 1,\n",
              " 'count(p)': 0,\n",
              " 'count(q)': 0,\n",
              " 'count(r)': 0,\n",
              " 'count(s)': 0,\n",
              " 'count(t)': 0,\n",
              " 'count(u)': 0,\n",
              " 'count(v)': 0,\n",
              " 'count(w)': 0,\n",
              " 'count(x)': 0,\n",
              " 'count(y)': 0,\n",
              " 'count(z)': 0,\n",
              " 'first_letter': 'j',\n",
              " 'has(a)': False,\n",
              " 'has(b)': False,\n",
              " 'has(c)': False,\n",
              " 'has(d)': False,\n",
              " 'has(e)': False,\n",
              " 'has(f)': False,\n",
              " 'has(g)': False,\n",
              " 'has(h)': True,\n",
              " 'has(i)': False,\n",
              " 'has(j)': True,\n",
              " 'has(k)': False,\n",
              " 'has(l)': False,\n",
              " 'has(m)': False,\n",
              " 'has(n)': True,\n",
              " 'has(o)': True,\n",
              " 'has(p)': False,\n",
              " 'has(q)': False,\n",
              " 'has(r)': False,\n",
              " 'has(s)': False,\n",
              " 'has(t)': False,\n",
              " 'has(u)': False,\n",
              " 'has(v)': False,\n",
              " 'has(w)': False,\n",
              " 'has(x)': False,\n",
              " 'has(y)': False,\n",
              " 'has(z)': False,\n",
              " 'last_letter': 'n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "4xpX7y-pwxC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e9b977b-6437-4a47-b5f1-0a47ca5d718d"
      },
      "cell_type": "code",
      "source": [
        ">>> featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
        ">>> train_set, test_set = featuresets[500:], featuresets[:500]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "etMBwwqZw1jB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> train_names = labeled_names[1500:]\n",
        ">>> devtest_names = labeled_names[500:1500]\n",
        ">>> test_names = labeled_names[:500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "27qw5gVDw3k1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ac8e433-d944-44a8-f5fe-a558c76c0f77"
      },
      "cell_type": "code",
      "source": [
        ">>> train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        ">>> devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        ">>> test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f-YbWHLrw6bx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> errors = []\n",
        ">>> for (name, tag) in devtest_names:\n",
        "...     guess = classifier.classify(gender_features(name))\n",
        "...     if guess != tag:\n",
        "...         errors.append( (tag, guess, name) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x4ZXS4_Rw90e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4061
        },
        "outputId": "e0bcc122-e4ab-4106-884d-5bfd5f422921"
      },
      "cell_type": "code",
      "source": [
        ">>> for (tag, guess, name) in sorted(errors):\n",
        "...     print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct=female   guess=male     name=Aeriell                       \n",
            "correct=female   guess=male     name=Agnes                         \n",
            "correct=female   guess=male     name=Alis                          \n",
            "correct=female   guess=male     name=Angel                         \n",
            "correct=female   guess=male     name=Annabal                       \n",
            "correct=female   guess=male     name=Ardys                         \n",
            "correct=female   guess=male     name=Avis                          \n",
            "correct=female   guess=male     name=Avril                         \n",
            "correct=female   guess=male     name=Ayn                           \n",
            "correct=female   guess=male     name=Bren                          \n",
            "correct=female   guess=male     name=Brit                          \n",
            "correct=female   guess=male     name=Brooks                        \n",
            "correct=female   guess=male     name=Carleen                       \n",
            "correct=female   guess=male     name=Carlynn                       \n",
            "correct=female   guess=male     name=Carmon                        \n",
            "correct=female   guess=male     name=Carol-Jean                    \n",
            "correct=female   guess=male     name=Carroll                       \n",
            "correct=female   guess=male     name=Cathyleen                     \n",
            "correct=female   guess=male     name=Catlin                        \n",
            "correct=female   guess=male     name=Charleen                      \n",
            "correct=female   guess=male     name=Charmion                      \n",
            "correct=female   guess=male     name=Chris                         \n",
            "correct=female   guess=male     name=Christen                      \n",
            "correct=female   guess=male     name=Chrysler                      \n",
            "correct=female   guess=male     name=Clem                          \n",
            "correct=female   guess=male     name=Coral                         \n",
            "correct=female   guess=male     name=Coriss                        \n",
            "correct=female   guess=male     name=Cristin                       \n",
            "correct=female   guess=male     name=Cyb                           \n",
            "correct=female   guess=male     name=Danell                        \n",
            "correct=female   guess=male     name=Dareen                        \n",
            "correct=female   guess=male     name=Dorit                         \n",
            "correct=female   guess=male     name=Drew                          \n",
            "correct=female   guess=male     name=Emlyn                         \n",
            "correct=female   guess=male     name=Emlynn                        \n",
            "correct=female   guess=male     name=Eran                          \n",
            "correct=female   guess=male     name=Eryn                          \n",
            "correct=female   guess=male     name=Estel                         \n",
            "correct=female   guess=male     name=Ethelind                      \n",
            "correct=female   guess=male     name=Evangelin                     \n",
            "correct=female   guess=male     name=Farrand                       \n",
            "correct=female   guess=male     name=Faun                          \n",
            "correct=female   guess=male     name=Fawn                          \n",
            "correct=female   guess=male     name=Fern                          \n",
            "correct=female   guess=male     name=Francis                       \n",
            "correct=female   guess=male     name=Glen                          \n",
            "correct=female   guess=male     name=Glennis                       \n",
            "correct=female   guess=male     name=Grissel                       \n",
            "correct=female   guess=male     name=Hazel                         \n",
            "correct=female   guess=male     name=Heather                       \n",
            "correct=female   guess=male     name=Hesther                       \n",
            "correct=female   guess=male     name=Hildagard                     \n",
            "correct=female   guess=male     name=Honor                         \n",
            "correct=female   guess=male     name=Ingeborg                      \n",
            "correct=female   guess=male     name=Isador                        \n",
            "correct=female   guess=male     name=Ivett                         \n",
            "correct=female   guess=male     name=Jacquelynn                    \n",
            "correct=female   guess=male     name=Janeen                        \n",
            "correct=female   guess=male     name=Jaquelin                      \n",
            "correct=female   guess=male     name=Jessalin                      \n",
            "correct=female   guess=male     name=Jo                            \n",
            "correct=female   guess=male     name=Joannes                       \n",
            "correct=female   guess=male     name=Joelynn                       \n",
            "correct=female   guess=male     name=Jolynn                        \n",
            "correct=female   guess=male     name=Joslyn                        \n",
            "correct=female   guess=male     name=Josselyn                      \n",
            "correct=female   guess=male     name=Karilynn                      \n",
            "correct=female   guess=male     name=Karyn                         \n",
            "correct=female   guess=male     name=Katalin                       \n",
            "correct=female   guess=male     name=Katharyn                      \n",
            "correct=female   guess=male     name=Kaylyn                        \n",
            "correct=female   guess=male     name=Kerrill                       \n",
            "correct=female   guess=male     name=Kial                          \n",
            "correct=female   guess=male     name=Kirstin                       \n",
            "correct=female   guess=male     name=Kylynn                        \n",
            "correct=female   guess=male     name=Lib                           \n",
            "correct=female   guess=male     name=Linell                        \n",
            "correct=female   guess=male     name=Linnell                       \n",
            "correct=female   guess=male     name=Lorrin                        \n",
            "correct=female   guess=male     name=Lulu                          \n",
            "correct=female   guess=male     name=Lynett                        \n",
            "correct=female   guess=male     name=Mabel                         \n",
            "correct=female   guess=male     name=Madelin                       \n",
            "correct=female   guess=male     name=Madelon                       \n",
            "correct=female   guess=male     name=Madlin                        \n",
            "correct=female   guess=male     name=Mair                          \n",
            "correct=female   guess=male     name=Marget                        \n",
            "correct=female   guess=male     name=Mariam                        \n",
            "correct=female   guess=male     name=Maridel                       \n",
            "correct=female   guess=male     name=Marigold                      \n",
            "correct=female   guess=male     name=Maris                         \n",
            "correct=female   guess=male     name=Marlo                         \n",
            "correct=female   guess=male     name=Mavis                         \n",
            "correct=female   guess=male     name=Mead                          \n",
            "correct=female   guess=male     name=Meggan                        \n",
            "correct=female   guess=male     name=Meghann                       \n",
            "correct=female   guess=male     name=Mildred                       \n",
            "correct=female   guess=male     name=Mildrid                       \n",
            "correct=female   guess=male     name=Moreen                        \n",
            "correct=female   guess=male     name=Morgen                        \n",
            "correct=female   guess=male     name=Mureil                        \n",
            "correct=female   guess=male     name=Nell                          \n",
            "correct=female   guess=male     name=Pat                           \n",
            "correct=female   guess=male     name=Pearl                         \n",
            "correct=female   guess=male     name=Persis                        \n",
            "correct=female   guess=male     name=Phyllys                       \n",
            "correct=female   guess=male     name=Renel                         \n",
            "correct=female   guess=male     name=Riannon                       \n",
            "correct=female   guess=male     name=Rochell                       \n",
            "correct=female   guess=male     name=Rozalin                       \n",
            "correct=female   guess=male     name=Ruthann                       \n",
            "correct=female   guess=male     name=Sherilyn                      \n",
            "correct=female   guess=male     name=Sibyl                         \n",
            "correct=female   guess=male     name=Stoddard                      \n",
            "correct=female   guess=male     name=Venus                         \n",
            "correct=female   guess=male     name=Vivian                        \n",
            "correct=female   guess=male     name=Vivyan                        \n",
            "correct=female   guess=male     name=Wandis                        \n",
            "correct=female   guess=male     name=Wileen                        \n",
            "correct=female   guess=male     name=Wren                          \n",
            "correct=male     guess=female   name=Abe                           \n",
            "correct=male     guess=female   name=Ajai                          \n",
            "correct=male     guess=female   name=Andrea                        \n",
            "correct=male     guess=female   name=Arie                          \n",
            "correct=male     guess=female   name=Ashby                         \n",
            "correct=male     guess=female   name=Aubrey                        \n",
            "correct=male     guess=female   name=Bay                           \n",
            "correct=male     guess=female   name=Berkie                        \n",
            "correct=male     guess=female   name=Billie                        \n",
            "correct=male     guess=female   name=Bobbie                        \n",
            "correct=male     guess=female   name=Brice                         \n",
            "correct=male     guess=female   name=Carmine                       \n",
            "correct=male     guess=female   name=Christie                      \n",
            "correct=male     guess=female   name=Christoph                     \n",
            "correct=male     guess=female   name=Clay                          \n",
            "correct=male     guess=female   name=Claybourne                    \n",
            "correct=male     guess=female   name=Corby                         \n",
            "correct=male     guess=female   name=Darby                         \n",
            "correct=male     guess=female   name=Davidde                       \n",
            "correct=male     guess=female   name=Deane                         \n",
            "correct=male     guess=female   name=Demetri                       \n",
            "correct=male     guess=female   name=Denny                         \n",
            "correct=male     guess=female   name=Doyle                         \n",
            "correct=male     guess=female   name=Eustace                       \n",
            "correct=male     guess=female   name=Ferdy                         \n",
            "correct=male     guess=female   name=Filmore                       \n",
            "correct=male     guess=female   name=Georgy                        \n",
            "correct=male     guess=female   name=Gere                          \n",
            "correct=male     guess=female   name=Germaine                      \n",
            "correct=male     guess=female   name=Gordie                        \n",
            "correct=male     guess=female   name=Gregory                       \n",
            "correct=male     guess=female   name=Gustave                       \n",
            "correct=male     guess=female   name=Helmuth                       \n",
            "correct=male     guess=female   name=Hermy                         \n",
            "correct=male     guess=female   name=Hillery                       \n",
            "correct=male     guess=female   name=Howie                         \n",
            "correct=male     guess=female   name=Hymie                         \n",
            "correct=male     guess=female   name=Ira                           \n",
            "correct=male     guess=female   name=Irvine                        \n",
            "correct=male     guess=female   name=Isaiah                        \n",
            "correct=male     guess=female   name=Jeremy                        \n",
            "correct=male     guess=female   name=Jerrome                       \n",
            "correct=male     guess=female   name=Jerzy                         \n",
            "correct=male     guess=female   name=Jeth                          \n",
            "correct=male     guess=female   name=Jimmy                         \n",
            "correct=male     guess=female   name=Jorge                         \n",
            "correct=male     guess=female   name=Judith                        \n",
            "correct=male     guess=female   name=Jule                          \n",
            "correct=male     guess=female   name=Kelly                         \n",
            "correct=male     guess=female   name=Laurance                      \n",
            "correct=male     guess=female   name=Lay                           \n",
            "correct=male     guess=female   name=Lindy                         \n",
            "correct=male     guess=female   name=Luigi                         \n",
            "correct=male     guess=female   name=Luke                          \n",
            "correct=male     guess=female   name=Mace                          \n",
            "correct=male     guess=female   name=Mahesh                        \n",
            "correct=male     guess=female   name=Marietta                      \n",
            "correct=male     guess=female   name=Marlowe                       \n",
            "correct=male     guess=female   name=Martie                        \n",
            "correct=male     guess=female   name=Maurice                       \n",
            "correct=male     guess=female   name=Maxie                         \n",
            "correct=male     guess=female   name=Merry                         \n",
            "correct=male     guess=female   name=Micah                         \n",
            "correct=male     guess=female   name=Mikey                         \n",
            "correct=male     guess=female   name=Mitch                         \n",
            "correct=male     guess=female   name=Montague                      \n",
            "correct=male     guess=female   name=Monty                         \n",
            "correct=male     guess=female   name=Morley                        \n",
            "correct=male     guess=female   name=Murphy                        \n",
            "correct=male     guess=female   name=Mustafa                       \n",
            "correct=male     guess=female   name=Nickey                        \n",
            "correct=male     guess=female   name=Nickie                        \n",
            "correct=male     guess=female   name=Nikolai                       \n",
            "correct=male     guess=female   name=Normie                        \n",
            "correct=male     guess=female   name=Obadiah                       \n",
            "correct=male     guess=female   name=Osborne                       \n",
            "correct=male     guess=female   name=Ozzie                         \n",
            "correct=male     guess=female   name=Partha                        \n",
            "correct=male     guess=female   name=Percy                         \n",
            "correct=male     guess=female   name=Piggy                         \n",
            "correct=male     guess=female   name=Prentice                      \n",
            "correct=male     guess=female   name=Ramsay                        \n",
            "correct=male     guess=female   name=Ray                           \n",
            "correct=male     guess=female   name=Rey                           \n",
            "correct=male     guess=female   name=Ricky                         \n",
            "correct=male     guess=female   name=Roderich                      \n",
            "correct=male     guess=female   name=Rodge                         \n",
            "correct=male     guess=female   name=Rodolph                       \n",
            "correct=male     guess=female   name=Roice                         \n",
            "correct=male     guess=female   name=Ronny                         \n",
            "correct=male     guess=female   name=Rory                          \n",
            "correct=male     guess=female   name=Ruddy                         \n",
            "correct=male     guess=female   name=Sascha                        \n",
            "correct=male     guess=female   name=See                           \n",
            "correct=male     guess=female   name=Shayne                        \n",
            "correct=male     guess=female   name=Shorty                        \n",
            "correct=male     guess=female   name=Skelly                        \n",
            "correct=male     guess=female   name=Sollie                        \n",
            "correct=male     guess=female   name=Solly                         \n",
            "correct=male     guess=female   name=Sonnie                        \n",
            "correct=male     guess=female   name=Stevy                         \n",
            "correct=male     guess=female   name=Tammie                        \n",
            "correct=male     guess=female   name=Tarrance                      \n",
            "correct=male     guess=female   name=Teddie                        \n",
            "correct=male     guess=female   name=Thane                         \n",
            "correct=male     guess=female   name=Thorny                        \n",
            "correct=male     guess=female   name=Tony                          \n",
            "correct=male     guess=female   name=Tray                          \n",
            "correct=male     guess=female   name=Wash                          \n",
            "correct=male     guess=female   name=Westbrooke                    \n",
            "correct=male     guess=female   name=Whitby                        \n",
            "correct=male     guess=female   name=Wojciech                      \n",
            "correct=male     guess=female   name=Yardley                       \n",
            "correct=male     guess=female   name=Zolly                         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_mk5auGtw_vP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> def gender_features(word):\n",
        "...     return {'suffix1': word[-1:],\n",
        "...             'suffix2': word[-2:]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M0t7Q2JVxF0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51723060-694b-462f-d9bb-c56223dbfe10"
      },
      "cell_type": "code",
      "source": [
        ">>> train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        ">>> devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FKOdV0YNxM4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "99fb16dd-06e8-478e-b4d8-c28be0618aba"
      },
      "cell_type": "code",
      "source": [
        "  >>> import nltk\n",
        "  >>> nltk.download('movie_reviews')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "NDL7FuYkxHzq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> from nltk.corpus import movie_reviews\n",
        ">>> documents = [(list(movie_reviews.words(fileid)), category)\n",
        "...              for category in movie_reviews.categories()\n",
        "...              for fileid in movie_reviews.fileids(category)]\n",
        ">>> random.shuffle(documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h6J8kF8txKIe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:2000] \n",
        "\n",
        "def document_features(document): \n",
        "    document_words = set(document) \n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zcrwWOPtxSEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c88e0e78-3f74-451d-eb73-73d18b18eaf3"
      },
      "cell_type": "code",
      "source": [
        "print(document_features(movie_reviews.words('pos/cv957_8737.txt')))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'contains(plot)': True, 'contains(:)': True, 'contains(two)': True, 'contains(teen)': False, 'contains(couples)': False, 'contains(go)': False, 'contains(to)': True, 'contains(a)': True, 'contains(church)': False, 'contains(party)': False, 'contains(,)': True, 'contains(drink)': False, 'contains(and)': True, 'contains(then)': True, 'contains(drive)': False, 'contains(.)': True, 'contains(they)': True, 'contains(get)': True, 'contains(into)': True, 'contains(an)': True, 'contains(accident)': False, 'contains(one)': True, 'contains(of)': True, 'contains(the)': True, 'contains(guys)': False, 'contains(dies)': False, 'contains(but)': True, 'contains(his)': True, 'contains(girlfriend)': True, 'contains(continues)': False, 'contains(see)': False, 'contains(him)': True, 'contains(in)': True, 'contains(her)': False, 'contains(life)': False, 'contains(has)': True, 'contains(nightmares)': False, 'contains(what)': True, \"contains(')\": True, 'contains(s)': True, 'contains(deal)': False, 'contains(?)': False, 'contains(watch)': True, 'contains(movie)': True, 'contains(\")': True, 'contains(sorta)': False, 'contains(find)': False, 'contains(out)': True, 'contains(critique)': False, 'contains(mind)': False, 'contains(-)': True, 'contains(fuck)': False, 'contains(for)': True, 'contains(generation)': False, 'contains(that)': True, 'contains(touches)': False, 'contains(on)': True, 'contains(very)': True, 'contains(cool)': False, 'contains(idea)': True, 'contains(presents)': False, 'contains(it)': True, 'contains(bad)': False, 'contains(package)': False, 'contains(which)': True, 'contains(is)': True, 'contains(makes)': False, 'contains(this)': True, 'contains(review)': False, 'contains(even)': False, 'contains(harder)': False, 'contains(write)': False, 'contains(since)': False, 'contains(i)': False, 'contains(generally)': False, 'contains(applaud)': False, 'contains(films)': False, 'contains(attempt)': False, 'contains(break)': False, 'contains(mold)': False, 'contains(mess)': False, 'contains(with)': True, 'contains(your)': False, 'contains(head)': False, 'contains(such)': False, 'contains(()': True, 'contains(lost)': False, 'contains(highway)': False, 'contains(&)': False, 'contains(memento)': False, 'contains())': True, 'contains(there)': True, 'contains(are)': True, 'contains(good)': False, 'contains(ways)': False, 'contains(making)': True, 'contains(all)': True, 'contains(types)': False, 'contains(these)': False, 'contains(folks)': False, 'contains(just)': True, 'contains(didn)': False, 'contains(t)': False, 'contains(snag)': False, 'contains(correctly)': False, 'contains(seem)': False, 'contains(have)': True, 'contains(taken)': False, 'contains(pretty)': False, 'contains(neat)': False, 'contains(concept)': False, 'contains(executed)': False, 'contains(terribly)': False, 'contains(so)': False, 'contains(problems)': True, 'contains(well)': True, 'contains(its)': False, 'contains(main)': False, 'contains(problem)': False, 'contains(simply)': False, 'contains(too)': False, 'contains(jumbled)': False, 'contains(starts)': False, 'contains(off)': False, 'contains(normal)': False, 'contains(downshifts)': False, 'contains(fantasy)': False, 'contains(world)': True, 'contains(you)': True, 'contains(as)': True, 'contains(audience)': False, 'contains(member)': False, 'contains(no)': False, 'contains(going)': False, 'contains(dreams)': False, 'contains(characters)': False, 'contains(coming)': False, 'contains(back)': False, 'contains(from)': True, 'contains(dead)': False, 'contains(others)': True, 'contains(who)': True, 'contains(look)': True, 'contains(like)': True, 'contains(strange)': False, 'contains(apparitions)': False, 'contains(disappearances)': False, 'contains(looooot)': False, 'contains(chase)': True, 'contains(scenes)': False, 'contains(tons)': False, 'contains(weird)': False, 'contains(things)': True, 'contains(happen)': False, 'contains(most)': True, 'contains(not)': True, 'contains(explained)': False, 'contains(now)': False, 'contains(personally)': False, 'contains(don)': False, 'contains(trying)': False, 'contains(unravel)': False, 'contains(film)': False, 'contains(every)': False, 'contains(when)': True, 'contains(does)': False, 'contains(give)': False, 'contains(me)': True, 'contains(same)': True, 'contains(clue)': False, 'contains(over)': False, 'contains(again)': False, 'contains(kind)': True, 'contains(fed)': False, 'contains(up)': False, 'contains(after)': False, 'contains(while)': True, 'contains(biggest)': False, 'contains(obviously)': False, 'contains(got)': True, 'contains(big)': False, 'contains(secret)': False, 'contains(hide)': False, 'contains(seems)': False, 'contains(want)': False, 'contains(completely)': False, 'contains(until)': False, 'contains(final)': False, 'contains(five)': False, 'contains(minutes)': False, 'contains(do)': True, 'contains(make)': True, 'contains(entertaining)': False, 'contains(thrilling)': False, 'contains(or)': False, 'contains(engaging)': False, 'contains(meantime)': False, 'contains(really)': False, 'contains(sad)': False, 'contains(part)': False, 'contains(arrow)': False, 'contains(both)': False, 'contains(dig)': False, 'contains(flicks)': False, 'contains(we)': False, 'contains(actually)': True, 'contains(figured)': False, 'contains(by)': True, 'contains(half)': False, 'contains(way)': True, 'contains(point)': False, 'contains(strangeness)': False, 'contains(did)': False, 'contains(start)': True, 'contains(little)': True, 'contains(bit)': False, 'contains(sense)': False, 'contains(still)': False, 'contains(more)': False, 'contains(guess)': False, 'contains(bottom)': False, 'contains(line)': False, 'contains(movies)': True, 'contains(should)': False, 'contains(always)': False, 'contains(sure)': False, 'contains(before)': False, 'contains(given)': False, 'contains(password)': False, 'contains(enter)': False, 'contains(understanding)': False, 'contains(mean)': False, 'contains(showing)': False, 'contains(melissa)': False, 'contains(sagemiller)': False, 'contains(running)': False, 'contains(away)': False, 'contains(visions)': False, 'contains(about)': True, 'contains(20)': False, 'contains(throughout)': False, 'contains(plain)': False, 'contains(lazy)': False, 'contains(!)': True, 'contains(okay)': False, 'contains(people)': False, 'contains(chasing)': False, 'contains(know)': False, 'contains(need)': False, 'contains(how)': True, 'contains(giving)': False, 'contains(us)': True, 'contains(different)': False, 'contains(offering)': False, 'contains(further)': False, 'contains(insight)': False, 'contains(down)': False, 'contains(apparently)': False, 'contains(studio)': False, 'contains(took)': False, 'contains(director)': False, 'contains(chopped)': False, 'contains(themselves)': False, 'contains(shows)': False, 'contains(might)': False, 'contains(ve)': False, 'contains(been)': False, 'contains(decent)': False, 'contains(here)': True, 'contains(somewhere)': False, 'contains(suits)': False, 'contains(decided)': False, 'contains(turning)': False, 'contains(music)': False, 'contains(video)': False, 'contains(edge)': False, 'contains(would)': False, 'contains(actors)': False, 'contains(although)': False, 'contains(wes)': False, 'contains(bentley)': False, 'contains(seemed)': False, 'contains(be)': True, 'contains(playing)': True, 'contains(exact)': False, 'contains(character)': False, 'contains(he)': True, 'contains(american)': False, 'contains(beauty)': False, 'contains(only)': True, 'contains(new)': False, 'contains(neighborhood)': False, 'contains(my)': False, 'contains(kudos)': False, 'contains(holds)': False, 'contains(own)': True, 'contains(entire)': False, 'contains(feeling)': False, 'contains(unraveling)': False, 'contains(overall)': False, 'contains(doesn)': False, 'contains(stick)': False, 'contains(because)': False, 'contains(entertain)': False, 'contains(confusing)': False, 'contains(rarely)': False, 'contains(excites)': False, 'contains(feels)': False, 'contains(redundant)': False, 'contains(runtime)': False, 'contains(despite)': False, 'contains(ending)': False, 'contains(explanation)': False, 'contains(craziness)': False, 'contains(came)': False, 'contains(oh)': False, 'contains(horror)': False, 'contains(slasher)': False, 'contains(flick)': False, 'contains(packaged)': False, 'contains(someone)': False, 'contains(assuming)': False, 'contains(genre)': False, 'contains(hot)': False, 'contains(kids)': False, 'contains(also)': True, 'contains(wrapped)': False, 'contains(production)': False, 'contains(years)': False, 'contains(ago)': False, 'contains(sitting)': False, 'contains(shelves)': False, 'contains(ever)': True, 'contains(whatever)': False, 'contains(skip)': False, 'contains(where)': True, 'contains(joblo)': False, 'contains(nightmare)': False, 'contains(elm)': False, 'contains(street)': False, 'contains(3)': False, 'contains(7)': False, 'contains(/)': False, 'contains(10)': False, 'contains(blair)': False, 'contains(witch)': False, 'contains(2)': False, 'contains(crow)': False, 'contains(9)': False, 'contains(salvation)': False, 'contains(4)': False, 'contains(stir)': False, 'contains(echoes)': False, 'contains(8)': False, 'contains(happy)': False, 'contains(bastard)': False, 'contains(quick)': True, 'contains(damn)': False, 'contains(y2k)': False, 'contains(bug)': False, 'contains(starring)': False, 'contains(jamie)': False, 'contains(lee)': False, 'contains(curtis)': False, 'contains(another)': False, 'contains(baldwin)': False, 'contains(brother)': False, 'contains(william)': False, 'contains(time)': False, 'contains(story)': False, 'contains(regarding)': False, 'contains(crew)': False, 'contains(tugboat)': False, 'contains(comes)': False, 'contains(across)': False, 'contains(deserted)': False, 'contains(russian)': False, 'contains(tech)': False, 'contains(ship)': False, 'contains(kick)': False, 'contains(power)': False, 'contains(within)': False, 'contains(gore)': False, 'contains(bringing)': False, 'contains(few)': False, 'contains(action)': True, 'contains(sequences)': False, 'contains(virus)': False, 'contains(empty)': False, 'contains(flash)': False, 'contains(substance)': False, 'contains(why)': False, 'contains(was)': False, 'contains(middle)': False, 'contains(nowhere)': False, 'contains(origin)': False, 'contains(pink)': False, 'contains(flashy)': False, 'contains(thing)': False, 'contains(hit)': False, 'contains(mir)': False, 'contains(course)': True, 'contains(donald)': False, 'contains(sutherland)': False, 'contains(stumbling)': False, 'contains(around)': False, 'contains(drunkenly)': False, 'contains(hey)': False, 'contains(let)': False, 'contains(some)': False, 'contains(robots)': False, 'contains(acting)': False, 'contains(below)': False, 'contains(average)': False, 'contains(likes)': False, 'contains(re)': True, 'contains(likely)': False, 'contains(work)': False, 'contains(halloween)': False, 'contains(h20)': False, 'contains(wasted)': False, 'contains(real)': False, 'contains(star)': False, 'contains(stan)': False, 'contains(winston)': False, 'contains(robot)': False, 'contains(design)': False, 'contains(schnazzy)': False, 'contains(cgi)': False, 'contains(occasional)': False, 'contains(shot)': False, 'contains(picking)': False, 'contains(brain)': False, 'contains(if)': True, 'contains(body)': False, 'contains(parts)': False, 'contains(turn)': False, 'contains(otherwise)': False, 'contains(much)': False, 'contains(sunken)': False, 'contains(jaded)': False, 'contains(viewer)': False, 'contains(thankful)': False, 'contains(invention)': False, 'contains(timex)': False, 'contains(indiglo)': False, 'contains(based)': False, 'contains(late)': False, 'contains(1960)': False, 'contains(television)': False, 'contains(show)': False, 'contains(name)': False, 'contains(mod)': False, 'contains(squad)': False, 'contains(tells)': False, 'contains(tale)': False, 'contains(three)': False, 'contains(reformed)': False, 'contains(criminals)': False, 'contains(under)': False, 'contains(employ)': False, 'contains(police)': False, 'contains(undercover)': True, 'contains(however)': True, 'contains(wrong)': True, 'contains(evidence)': False, 'contains(gets)': True, 'contains(stolen)': False, 'contains(immediately)': False, 'contains(suspicion)': False, 'contains(ads)': False, 'contains(cuts)': False, 'contains(claire)': False, 'contains(dane)': False, 'contains(nice)': False, 'contains(hair)': False, 'contains(cute)': False, 'contains(outfits)': False, 'contains(car)': False, 'contains(chases)': False, 'contains(stuff)': False, 'contains(blowing)': False, 'contains(sounds)': False, 'contains(first)': False, 'contains(fifteen)': False, 'contains(quickly)': False, 'contains(becomes)': False, 'contains(apparent)': False, 'contains(certainly)': False, 'contains(slick)': False, 'contains(looking)': False, 'contains(complete)': False, 'contains(costumes)': False, 'contains(isn)': False, 'contains(enough)': False, 'contains(best)': True, 'contains(described)': False, 'contains(cross)': False, 'contains(between)': True, 'contains(hour)': False, 'contains(long)': False, 'contains(cop)': False, 'contains(stretched)': False, 'contains(span)': False, 'contains(single)': False, 'contains(clich)': False, 'contains(matter)': False, 'contains(elements)': False, 'contains(recycled)': False, 'contains(everything)': True, 'contains(already)': False, 'contains(seen)': False, 'contains(nothing)': False, 'contains(spectacular)': False, 'contains(sometimes)': False, 'contains(bordering)': False, 'contains(wooden)': False, 'contains(danes)': False, 'contains(omar)': False, 'contains(epps)': False, 'contains(deliver)': False, 'contains(their)': False, 'contains(lines)': False, 'contains(bored)': False, 'contains(transfers)': False, 'contains(onto)': False, 'contains(escape)': False, 'contains(relatively)': False, 'contains(unscathed)': False, 'contains(giovanni)': False, 'contains(ribisi)': False, 'contains(plays)': False, 'contains(resident)': False, 'contains(crazy)': False, 'contains(man)': False, 'contains(ultimately)': False, 'contains(being)': False, 'contains(worth)': True, 'contains(watching)': False, 'contains(unfortunately)': False, 'contains(save)': False, 'contains(convoluted)': False, 'contains(apart)': False, 'contains(occupying)': False, 'contains(screen)': True, 'contains(young)': False, 'contains(cast)': False, 'contains(clothes)': False, 'contains(hip)': False, 'contains(soundtrack)': False, 'contains(appears)': False, 'contains(geared)': False, 'contains(towards)': False, 'contains(teenage)': False, 'contains(mindset)': False, 'contains(r)': False, 'contains(rating)': False, 'contains(content)': False, 'contains(justify)': False, 'contains(juvenile)': False, 'contains(older)': False, 'contains(information)': False, 'contains(literally)': False, 'contains(spoon)': False, 'contains(hard)': False, 'contains(instead)': False, 'contains(telling)': False, 'contains(dialogue)': False, 'contains(poorly)': False, 'contains(written)': False, 'contains(extremely)': False, 'contains(predictable)': False, 'contains(progresses)': False, 'contains(won)': False, 'contains(care)': False, 'contains(heroes)': False, 'contains(any)': False, 'contains(jeopardy)': False, 'contains(ll)': False, 'contains(aren)': False, 'contains(basing)': False, 'contains(nobody)': False, 'contains(remembers)': False, 'contains(questionable)': False, 'contains(wisdom)': False, 'contains(especially)': True, 'contains(considers)': False, 'contains(target)': False, 'contains(fact)': False, 'contains(number)': False, 'contains(memorable)': False, 'contains(can)': False, 'contains(counted)': False, 'contains(hand)': False, 'contains(missing)': False, 'contains(finger)': False, 'contains(times)': False, 'contains(checked)': False, 'contains(six)': False, 'contains(clear)': False, 'contains(indication)': False, 'contains(them)': True, 'contains(than)': False, 'contains(cash)': False, 'contains(spending)': False, 'contains(dollar)': False, 'contains(judging)': False, 'contains(rash)': False, 'contains(awful)': False, 'contains(seeing)': True, 'contains(avoid)': False, 'contains(at)': False, 'contains(costs)': False, 'contains(quest)': False, 'contains(camelot)': False, 'contains(warner)': False, 'contains(bros)': False, 'contains(feature)': False, 'contains(length)': False, 'contains(fully)': False, 'contains(animated)': False, 'contains(steal)': False, 'contains(clout)': False, 'contains(disney)': False, 'contains(cartoon)': False, 'contains(empire)': False, 'contains(mouse)': False, 'contains(reason)': False, 'contains(worried)': False, 'contains(other)': True, 'contains(recent)': False, 'contains(challenger)': False, 'contains(throne)': False, 'contains(last)': False, 'contains(fall)': False, 'contains(promising)': False, 'contains(flawed)': False, 'contains(20th)': False, 'contains(century)': False, 'contains(fox)': False, 'contains(anastasia)': False, 'contains(hercules)': False, 'contains(lively)': False, 'contains(colorful)': False, 'contains(palate)': False, 'contains(had)': False, 'contains(beat)': False, 'contains(hands)': False, 'contains(crown)': False, 'contains(1997)': False, 'contains(piece)': False, 'contains(animation)': False, 'contains(year)': False, 'contains(contest)': False, 'contains(arrival)': False, 'contains(magic)': False, 'contains(kingdom)': False, 'contains(mediocre)': False, 'contains(--)': True, 'contains(d)': False, 'contains(pocahontas)': False, 'contains(those)': False, 'contains(keeping)': False, 'contains(score)': False, 'contains(nearly)': False, 'contains(dull)': False, 'contains(revolves)': False, 'contains(adventures)': False, 'contains(free)': False, 'contains(spirited)': False, 'contains(kayley)': False, 'contains(voiced)': False, 'contains(jessalyn)': False, 'contains(gilsig)': False, 'contains(early)': True, 'contains(daughter)': False, 'contains(belated)': False, 'contains(knight)': False, 'contains(king)': False, 'contains(arthur)': False, 'contains(round)': False, 'contains(table)': False, 'contains(dream)': False, 'contains(follow)': False, 'contains(father)': False, 'contains(footsteps)': False, 'contains(she)': True, 'contains(chance)': False, 'contains(evil)': False, 'contains(warlord)': False, 'contains(ruber)': False, 'contains(gary)': False, 'contains(oldman)': False, 'contains(ex)': False, 'contains(gone)': False, 'contains(steals)': False, 'contains(magical)': False, 'contains(sword)': False, 'contains(excalibur)': False, 'contains(accidentally)': False, 'contains(loses)': False, 'contains(dangerous)': True, 'contains(booby)': False, 'contains(trapped)': False, 'contains(forest)': False, 'contains(help)': True, 'contains(hunky)': False, 'contains(blind)': False, 'contains(timberland)': False, 'contains(dweller)': False, 'contains(garrett)': False, 'contains(carey)': False, 'contains(elwes)': False, 'contains(headed)': False, 'contains(dragon)': False, 'contains(eric)': False, 'contains(idle)': False, 'contains(rickles)': False, 'contains(arguing)': False, 'contains(itself)': False, 'contains(able)': False, 'contains(medieval)': False, 'contains(sexist)': False, 'contains(prove)': False, 'contains(fighter)': False, 'contains(side)': False, 'contains(pure)': False, 'contains(showmanship)': False, 'contains(essential)': False, 'contains(element)': False, 'contains(expected)': False, 'contains(climb)': False, 'contains(high)': False, 'contains(ranks)': False, 'contains(differentiates)': False, 'contains(something)': False, 'contains(saturday)': False, 'contains(morning)': False, 'contains(subpar)': False, 'contains(instantly)': False, 'contains(forgettable)': False, 'contains(songs)': False, 'contains(integrated)': False, 'contains(computerized)': False, 'contains(footage)': False, 'contains(compare)': False, 'contains(run)': False, 'contains(angry)': False, 'contains(ogre)': False, 'contains(herc)': False, 'contains(battle)': False, 'contains(hydra)': False, 'contains(rest)': False, 'contains(case)': False, 'contains(stink)': False, 'contains(none)': False, 'contains(remotely)': False, 'contains(interesting)': False, 'contains(race)': False, 'contains(bland)': False, 'contains(end)': False, 'contains(tie)': False, 'contains(win)': False, 'contains(comedy)': True, 'contains(shtick)': False, 'contains(awfully)': False, 'contains(cloying)': False, 'contains(least)': True, 'contains(signs)': False, 'contains(pulse)': False, 'contains(fans)': False, \"contains(-')\": False, 'contains(90s)': False, 'contains(tgif)': False, 'contains(will)': True, 'contains(thrilled)': False, 'contains(jaleel)': False, 'contains(urkel)': False, 'contains(white)': False, 'contains(bronson)': False, 'contains(balki)': False, 'contains(pinchot)': False, 'contains(sharing)': False, 'contains(nicely)': False, 'contains(realized)': False, 'contains(though)': False, 'contains(m)': False, 'contains(loss)': False, 'contains(recall)': False, 'contains(specific)': False, 'contains(providing)': False, 'contains(voice)': False, 'contains(talent)': False, 'contains(enthusiastic)': False, 'contains(paired)': False, 'contains(singers)': False, 'contains(sound)': False, 'contains(musical)': False, 'contains(moments)': False, 'contains(jane)': False, 'contains(seymour)': False, 'contains(celine)': False, 'contains(dion)': False, 'contains(must)': False, 'contains(strain)': False, 'contains(through)': False, 'contains(aside)': False, 'contains(children)': False, 'contains(probably)': False, 'contains(adults)': False, 'contains(grievous)': False, 'contains(error)': False, 'contains(lack)': False, 'contains(personality)': False, 'contains(learn)': False, 'contains(goes)': False, 'contains(synopsis)': False, 'contains(mentally)': False, 'contains(unstable)': False, 'contains(undergoing)': False, 'contains(psychotherapy)': False, 'contains(saves)': False, 'contains(boy)': False, 'contains(potentially)': False, 'contains(fatal)': False, 'contains(falls)': False, 'contains(love)': False, 'contains(mother)': False, 'contains(fledgling)': False, 'contains(restauranteur)': False, 'contains(unsuccessfully)': False, 'contains(attempting)': False, 'contains(gain)': False, 'contains(woman)': True, 'contains(favor)': False, 'contains(takes)': False, 'contains(pictures)': False, 'contains(kills)': False, 'contains(comments)': True, 'contains(stalked)': False, 'contains(yet)': False, 'contains(seemingly)': False, 'contains(endless)': True, 'contains(string)': False, 'contains(spurned)': False, 'contains(psychos)': False, 'contains(getting)': True, 'contains(revenge)': False, 'contains(type)': False, 'contains(stable)': False, 'contains(category)': False, 'contains(1990s)': False, 'contains(industry)': False, 'contains(theatrical)': False, 'contains(direct)': False, 'contains(proliferation)': False, 'contains(may)': False, 'contains(due)': False, 'contains(typically)': False, 'contains(inexpensive)': False, 'contains(produce)': False, 'contains(special)': False, 'contains(effects)': False, 'contains(stars)': False, 'contains(serve)': False, 'contains(vehicles)': False, 'contains(nudity)': False, 'contains(allowing)': False, 'contains(frequent)': False, 'contains(night)': False, 'contains(cable)': False, 'contains(wavers)': False, 'contains(slightly)': False, 'contains(norm)': False, 'contains(respect)': False, 'contains(psycho)': False, 'contains(never)': True, 'contains(affair)': False, 'contains(;)': False, 'contains(contrary)': False, 'contains(rejected)': False, 'contains(rather)': False, 'contains(lover)': False, 'contains(wife)': True, 'contains(husband)': False, 'contains(entry)': False, 'contains(doomed)': False, 'contains(collect)': False, 'contains(dust)': False, 'contains(viewed)': False, 'contains(midnight)': False, 'contains(provide)': False, 'contains(suspense)': False, 'contains(sets)': False, 'contains(interspersed)': False, 'contains(opening)': False, 'contains(credits)': False, 'contains(instance)': False, 'contains(serious)': False, 'contains(sounding)': False, 'contains(narrator)': False, 'contains(spouts)': False, 'contains(statistics)': False, 'contains(stalkers)': False, 'contains(ponders)': False, 'contains(cause)': False, 'contains(stalk)': False, 'contains(implicitly)': False, 'contains(implied)': False, 'contains(men)': False, 'contains(shown)': False, 'contains(snapshot)': False, 'contains(actor)': False, 'contains(jay)': False, 'contains(underwood)': False, 'contains(states)': False, 'contains(daryl)': False, 'contains(gleason)': False, 'contains(stalker)': False, 'contains(brooke)': False, 'contains(daniels)': False, 'contains(meant)': False, 'contains(called)': False, 'contains(guesswork)': False, 'contains(required)': False, 'contains(proceeds)': False, 'contains(begins)': False, 'contains(obvious)': False, 'contains(sequence)': False, 'contains(contrived)': False, 'contains(quite)': False, 'contains(brings)': False, 'contains(victim)': False, 'contains(together)': False, 'contains(obsesses)': False, 'contains(follows)': False, 'contains(tries)': True, 'contains(woo)': False, 'contains(plans)': False, 'contains(become)': False, 'contains(desperate)': False, 'contains(elaborate)': False, 'contains(include)': False, 'contains(cliche)': False, 'contains(murdered)': False, 'contains(pet)': False, 'contains(require)': False, 'contains(found)': False, 'contains(exception)': False, 'contains(cat)': False, 'contains(shower)': False, 'contains(events)': False, 'contains(lead)': True, 'contains(inevitable)': False, 'contains(showdown)': False, 'contains(survives)': False, 'contains(invariably)': False, 'contains(conclusion)': False, 'contains(turkey)': False, 'contains(uniformly)': False, 'contains(adequate)': False, 'contains(anything)': False, 'contains(home)': False, 'contains(either)': False, 'contains(turns)': False, 'contains(toward)': False, 'contains(melodrama)': False, 'contains(overdoes)': False, 'contains(words)': False, 'contains(manages)': False, 'contains(creepy)': False, 'contains(pass)': False, 'contains(demands)': False, 'contains(maryam)': False, 'contains(abo)': False, 'contains(close)': False, 'contains(played)': True, 'contains(bond)': False, 'contains(chick)': False, 'contains(living)': False, 'contains(daylights)': False, 'contains(equally)': False, 'contains(title)': False, 'contains(ditzy)': False, 'contains(strong)': False, 'contains(independent)': False, 'contains(business)': False, 'contains(owner)': False, 'contains(needs)': False, 'contains(proceed)': False, 'contains(example)': False, 'contains(suspicions)': False, 'contains(ensure)': False, 'contains(use)': False, 'contains(excuse)': False, 'contains(decides)': False, 'contains(return)': False, 'contains(toolbox)': False, 'contains(left)': False, 'contains(place)': True, 'contains(house)': False, 'contains(leave)': False, 'contains(door)': False, 'contains(answers)': False, 'contains(opens)': False, 'contains(wanders)': False, 'contains(returns)': False, 'contains(enters)': False, 'contains(our)': False, 'contains(heroine)': False, 'contains(danger)': False, 'contains(somehow)': False, 'contains(parked)': False, 'contains(front)': False, 'contains(right)': False, 'contains(oblivious)': False, 'contains(presence)': False, 'contains(inside)': False, 'contains(whole)': False, 'contains(episode)': False, 'contains(places)': False, 'contains(incredible)': False, 'contains(suspension)': False, 'contains(disbelief)': False, 'contains(questions)': False, 'contains(validity)': False, 'contains(intelligence)': False, 'contains(receives)': False, 'contains(highly)': False, 'contains(derivative)': False, 'contains(somewhat)': False, 'contains(boring)': False, 'contains(cannot)': False, 'contains(watched)': False, 'contains(rated)': False, 'contains(mostly)': False, 'contains(several)': False, 'contains(murder)': False, 'contains(brief)': True, 'contains(strip)': False, 'contains(bar)': False, 'contains(offensive)': False, 'contains(many)': True, 'contains(thrillers)': False, 'contains(mood)': False, 'contains(stake)': False, 'contains(else)': False, 'contains(capsule)': True, 'contains(2176)': False, 'contains(planet)': False, 'contains(mars)': False, 'contains(taking)': False, 'contains(custody)': False, 'contains(accused)': False, 'contains(murderer)': False, 'contains(face)': False, 'contains(menace)': False, 'contains(lot)': False, 'contains(fighting)': False, 'contains(john)': False, 'contains(carpenter)': False, 'contains(reprises)': False, 'contains(ideas)': False, 'contains(previous)': False, 'contains(assault)': False, 'contains(precinct)': False, 'contains(13)': False, 'contains(homage)': False, 'contains(himself)': False, 'contains(0)': False, 'contains(+)': False, 'contains(believes)': False, 'contains(fight)': True, 'contains(horrible)': False, 'contains(writer)': False, 'contains(supposedly)': False, 'contains(expert)': False, 'contains(mistake)': False, 'contains(ghosts)': False, 'contains(drawn)': False, 'contains(humans)': False, 'contains(surprisingly)': False, 'contains(low)': False, 'contains(powered)': False, 'contains(alien)': False, 'contains(addition)': False, 'contains(anybody)': False, 'contains(made)': False, 'contains(grounds)': False, 'contains(sue)': False, 'contains(chock)': False, 'contains(full)': False, 'contains(pieces)': False, 'contains(prince)': False, 'contains(darkness)': False, 'contains(surprising)': False, 'contains(managed)': False, 'contains(fit)': False, 'contains(admittedly)': False, 'contains(novel)': False, 'contains(science)': False, 'contains(fiction)': False, 'contains(experience)': False, 'contains(terraformed)': False, 'contains(walk)': False, 'contains(surface)': False, 'contains(without)': False, 'contains(breathing)': False, 'contains(gear)': False, 'contains(budget)': False, 'contains(mentioned)': False, 'contains(gravity)': False, 'contains(increased)': False, 'contains(earth)': False, 'contains(easier)': False, 'contains(society)': False, 'contains(changed)': False, 'contains(advanced)': False, 'contains(culture)': False, 'contains(women)': False, 'contains(positions)': False, 'contains(control)': False, 'contains(view)': False, 'contains(stagnated)': False, 'contains(female)': False, 'contains(beyond)': False, 'contains(minor)': False, 'contains(technological)': False, 'contains(advances)': False, 'contains(less)': False, 'contains(175)': False, 'contains(expect)': False, 'contains(change)': False, 'contains(ten)': False, 'contains(basic)': False, 'contains(common)': False, 'contains(except)': False, 'contains(yes)': False, 'contains(replaced)': False, 'contains(tacky)': False, 'contains(rundown)': False, 'contains(martian)': False, 'contains(mining)': False, 'contains(colony)': False, 'contains(having)': False, 'contains(criminal)': False, 'contains(napolean)': False, 'contains(wilson)': False, 'contains(desolation)': False, 'contains(williams)': False, 'contains(facing)': False, 'contains(hoodlums)': False, 'contains(automatic)': False, 'contains(weapons)': False, 'contains(nature)': False, 'contains(behave)': False, 'contains(manner)': False, 'contains(essentially)': False, 'contains(human)': False, 'contains(savages)': False, 'contains(lapse)': False, 'contains(imagination)': False, 'contains(told)': False, 'contains(flashback)': False, 'contains(entirely)': False, 'contains(filmed)': False, 'contains(almost)': False, 'contains(tones)': False, 'contains(red)': False, 'contains(yellow)': False, 'contains(black)': False, 'contains(powerful)': False, 'contains(scene)': True, 'contains(train)': True, 'contains(rushing)': False, 'contains(heavy)': False, 'contains(sadly)': False, 'contains(buildup)': False, 'contains(terror)': False, 'contains(creates)': False, 'contains(looks)': True, 'contains(fugitive)': False, 'contains(wannabes)': False, 'contains(rock)': False, 'contains(band)': False, 'contains(kiss)': False, 'contains(building)': False, 'contains(bunch)': False, 'contains(sudden)': False, 'contains(jump)': False, 'contains(sucker)': False, 'contains(thinking)': False, 'contains(scary)': False, 'contains(happening)': False, 'contains(standard)': False, 'contains(haunted)': False, 'contains(shock)': False, 'contains(great)': True, 'contains(newer)': False, 'contains(unimpressive)': False, 'contains(digital)': False, 'contains(decapitations)': False, 'contains(fights)': False, 'contains(short)': False, 'contains(stretch)': False, 'contains(release)': False, 'contains(mission)': False, 'contains(panned)': False, 'contains(reviewers)': False, 'contains(better)': False, 'contains(rate)': False, 'contains(scale)': False, 'contains(following)': False, 'contains(showed)': False, 'contains(liked)': False, 'contains(moderately)': False, 'contains(classic)': False, 'contains(comment)': False, 'contains(twice)': False, 'contains(ask)': False, 'contains(yourself)': False, 'contains(8mm)': False, 'contains(eight)': True, 'contains(millimeter)': False, 'contains(wholesome)': False, 'contains(surveillance)': False, 'contains(sight)': False, 'contains(values)': False, 'contains(becoming)': False, 'contains(enmeshed)': False, 'contains(seedy)': False, 'contains(sleazy)': False, 'contains(underworld)': False, 'contains(hardcore)': False, 'contains(pornography)': False, 'contains(bubbling)': False, 'contains(beneath)': False, 'contains(town)': False, 'contains(americana)': False, 'contains(sordid)': False, 'contains(sick)': False, 'contains(depraved)': False, 'contains(necessarily)': False, 'contains(stop)': True, 'contains(order)': False, 'contains(satisfy)': False, 'contains(twisted)': False, 'contains(desires)': False, 'contains(position)': False, 'contains(influence)': False, 'contains(kinds)': False, 'contains(demented)': False, 'contains(talking)': False, 'contains(snuff)': False, 'contains(supposed)': False, 'contains(documentaries)': False, 'contains(victims)': False, 'contains(brutalized)': False, 'contains(killed)': False, 'contains(camera)': False, 'contains(joel)': False, 'contains(schumacher)': False, 'contains(credit)': False, 'contains(batman)': False, 'contains(robin)': False, 'contains(kill)': False, 'contains(forever)': False, 'contains(client)': False, 'contains(thirds)': False, 'contains(unwind)': False, 'contains(fairly)': True, 'contains(conventional)': False, 'contains(persons)': False, 'contains(drama)': False, 'contains(albeit)': False, 'contains(particularly)': False, 'contains(unsavory)': False, 'contains(core)': False, 'contains(threatening)': False, 'contains(along)': True, 'contains(explodes)': False, 'contains(violence)': False, 'contains(think)': False, 'contains(finally)': False, 'contains(tags)': False, 'contains(ridiculous)': False, 'contains(self)': False, 'contains(righteous)': False, 'contains(finale)': False, 'contains(drags)': False, 'contains(unpleasant)': False, 'contains(trust)': False, 'contains(waste)': False, 'contains(hours)': False, 'contains(nicolas)': False, 'contains(snake)': False, 'contains(eyes)': False, 'contains(cage)': False, 'contains(private)': False, 'contains(investigator)': False, 'contains(tom)': False, 'contains(welles)': False, 'contains(hired)': False, 'contains(wealthy)': False, 'contains(philadelphia)': False, 'contains(widow)': False, 'contains(determine)': False, 'contains(whether)': False, 'contains(reel)': False, 'contains(safe)': False, 'contains(documents)': False, 'contains(girl)': False, 'contains(assignment)': True, 'contains(factly)': False, 'contains(puzzle)': False, 'contains(neatly)': False, 'contains(specialized)': False, 'contains(skills)': False, 'contains(training)': False, 'contains(easy)': False, 'contains(cops)': False, 'contains(toilet)': False, 'contains(tanks)': False, 'contains(clues)': False, 'contains(deeper)': False, 'contains(digs)': False, 'contains(investigation)': False, 'contains(obsessed)': False, 'contains(george)': False, 'contains(c)': False, 'contains(scott)': False, 'contains(paul)': False, 'contains(schrader)': False, 'contains(occasionally)': False, 'contains(flickering)': False, 'contains(whirs)': False, 'contains(sprockets)': False, 'contains(winding)': False, 'contains(projector)': False, 'contains(reminding)': False, 'contains(task)': False, 'contains(hints)': False, 'contains(toll)': False, 'contains(lovely)': False, 'contains(catherine)': False, 'contains(keener)': False, 'contains(frustrated)': False, 'contains(cleveland)': False, 'contains(ugly)': False, 'contains(split)': False, 'contains(level)': False, 'contains(harrisburg)': False, 'contains(pa)': False, 'contains(condemn)': False, 'contains(condone)': False, 'contains(subject)': False, 'contains(exploits)': False, 'contains(irony)': False, 'contains(seven)': False, 'contains(scribe)': False, 'contains(andrew)': False, 'contains(kevin)': True, 'contains(walker)': False, 'contains(vision)': False, 'contains(lane)': False, 'contains(limited)': False, 'contains(hollywood)': False, 'contains(product)': False, 'contains(snippets)': False, 'contains(covering)': False, 'contains(later)': False, 'contains(joaquin)': False, 'contains(phoenix)': False, 'contains(far)': False, 'contains(adult)': False, 'contains(bookstore)': False, 'contains(flunky)': False, 'contains(max)': False, 'contains(california)': False, 'contains(cover)': False, 'contains(horrid)': False, 'contains(screened)': False, 'contains(familiar)': False, 'contains(revelation)': False, 'contains(sexual)': False, 'contains(deviants)': False, 'contains(indeed)': False, 'contains(monsters)': False, 'contains(everyday)': False, 'contains(neither)': False, 'contains(super)': False, 'contains(nor)': False, 'contains(shocking)': False, 'contains(banality)': False, 'contains(exactly)': False, 'contains(felt)': False, 'contains(weren)': False, 'contains(nine)': False, 'contains(laughs)': False, 'contains(months)': False, 'contains(terrible)': False, 'contains(mr)': False, 'contains(hugh)': False, 'contains(grant)': False, 'contains(huge)': False, 'contains(dork)': False, 'contains(oral)': False, 'contains(sex)': False, 'contains(prostitution)': False, 'contains(referring)': False, 'contains(bugs)': False, 'contains(annoying)': False, 'contains(adam)': False, 'contains(sandler)': False, 'contains(jim)': False, 'contains(carrey)': False, 'contains(eye)': False, 'contains(flutters)': False, 'contains(nervous)': False, 'contains(smiles)': False, 'contains(slapstick)': False, 'contains(fistfight)': False, 'contains(delivery)': False, 'contains(room)': False, 'contains(culminating)': False, 'contains(joan)': False, 'contains(cusack)': False, 'contains(lap)': False, 'contains(paid)': False, 'contains($)': False, 'contains(60)': False, 'contains(included)': False, 'contains(obscene)': False, 'contains(double)': False, 'contains(entendres)': False, 'contains(obstetrician)': False, 'contains(pregnant)': False, 'contains(pussy)': False, 'contains(size)': False, 'contains(hairs)': False, 'contains(coat)': False, 'contains(nonetheless)': False, 'contains(exchange)': False, 'contains(cookie)': False, 'contains(cutter)': False, 'contains(originality)': False, 'contains(humor)': False, 'contains(successful)': False, 'contains(child)': False, 'contains(psychiatrist)': False, 'contains(psychologist)': False, 'contains(scriptwriters)': False, 'contains(could)': False, 'contains(inject)': False, 'contains(unfunny)': False, 'contains(kid)': False, 'contains(dad)': False, 'contains(asshole)': False, 'contains(eyelashes)': False, 'contains(offers)': False, 'contains(smile)': False, 'contains(responds)': False, 'contains(english)': False, 'contains(accent)': False, 'contains(attitude)': False, 'contains(possibly)': False, 'contains(_huge_)': False, 'contains(beside)': False, 'contains(includes)': False, 'contains(needlessly)': False, 'contains(stupid)': False, 'contains(jokes)': False, 'contains(olds)': False, 'contains(everyone)': False, 'contains(shakes)': False, 'contains(anyway)': False, 'contains(finds)': False, 'contains(usual)': False, 'contains(reaction)': False, 'contains(fluttered)': False, 'contains(paves)': False, 'contains(possible)': False, 'contains(pregnancy)': False, 'contains(birth)': False, 'contains(gag)': False, 'contains(book)': False, 'contains(friend)': False, 'contains(arnold)': True, 'contains(provides)': False, 'contains(cacophonous)': False, 'contains(funny)': True, 'contains(beats)': False, 'contains(costumed)': False, 'contains(arnie)': False, 'contains(dinosaur)': False, 'contains(draw)': False, 'contains(parallels)': False, 'contains(toy)': False, 'contains(store)': False, 'contains(jeff)': False, 'contains(goldblum)': False, 'contains(hid)': False, 'contains(dreadful)': False, 'contains(hideaway)': False, 'contains(artist)': False, 'contains(fear)': False, 'contains(simultaneous)': False, 'contains(longing)': False, 'contains(commitment)': False, 'contains(doctor)': False, 'contains(recently)': False, 'contains(switch)': False, 'contains(veterinary)': False, 'contains(medicine)': False, 'contains(obstetrics)': False, 'contains(joke)': False, 'contains(old)': False, 'contains(foreign)': False, 'contains(guy)': True, 'contains(mispronounces)': False, 'contains(stereotype)': False, 'contains(say)': False, 'contains(yakov)': False, 'contains(smirnov)': False, 'contains(favorite)': False, 'contains(vodka)': False, 'contains(hence)': False, 'contains(take)': False, 'contains(volvo)': False, 'contains(nasty)': False, 'contains(unamusing)': False, 'contains(heads)': False, 'contains(simultaneously)': False, 'contains(groan)': False, 'contains(failure)': False, 'contains(loud)': False, 'contains(failed)': False, 'contains(uninspired)': False, 'contains(lunacy)': False, 'contains(sunset)': False, 'contains(boulevard)': False, 'contains(arrest)': False, 'contains(please)': False, 'contains(caught)': False, 'contains(pants)': False, 'contains(bring)': False, 'contains(theaters)': False, 'contains(faces)': False, 'contains(90)': False, 'contains(forced)': False, 'contains(unauthentic)': False, 'contains(anyone)': False, 'contains(q)': False, 'contains(80)': False, 'contains(sorry)': False, 'contains(money)': False, 'contains(unfulfilled)': False, 'contains(desire)': False, 'contains(spend)': False, 'contains(bucks)': False, 'contains(call)': False, 'contains(road)': False, 'contains(trip)': False, 'contains(walking)': False, 'contains(wounded)': False, 'contains(stellan)': False, 'contains(skarsg)': False, 'contains(rd)': False, 'contains(convincingly)': False, 'contains(zombified)': False, 'contains(drunken)': False, 'contains(loser)': False, 'contains(difficult)': True, 'contains(smelly)': False, 'contains(boozed)': False, 'contains(reliable)': False, 'contains(swedish)': False, 'contains(adds)': False, 'contains(depth)': False, 'contains(significance)': False, 'contains(plodding)': False, 'contains(aberdeen)': False, 'contains(sentimental)': False, 'contains(painfully)': False, 'contains(mundane)': False, 'contains(european)': False, 'contains(playwright)': False, 'contains(august)': False, 'contains(strindberg)': False, 'contains(built)': False, 'contains(career)': False, 'contains(families)': False, 'contains(relationships)': False, 'contains(paralyzed)': False, 'contains(secrets)': False, 'contains(unable)': False, 'contains(express)': False, 'contains(longings)': False, 'contains(accurate)': False, 'contains(reflection)': False, 'contains(strives)': False, 'contains(focusing)': False, 'contains(pairing)': False, 'contains(alcoholic)': False, 'contains(tomas)': False, 'contains(alienated)': False, 'contains(openly)': False, 'contains(hostile)': False, 'contains(yuppie)': False, 'contains(kaisa)': False, 'contains(lena)': False, 'contains(headey)': False, 'contains(gossip)': False, 'contains(haven)': False, 'contains(spoken)': False, 'contains(wouldn)': False, 'contains(norway)': False, 'contains(scotland)': False, 'contains(automobile)': False, 'contains(charlotte)': False, 'contains(rampling)': False, 'contains(sand)': False, 'contains(rotting)': False, 'contains(hospital)': False, 'contains(bed)': False, 'contains(cancer)': False, 'contains(soap)': False, 'contains(opera)': False, 'contains(twist)': False, 'contains(days)': False, 'contains(live)': False, 'contains(blitzed)': False, 'contains(step)': False, 'contains(foot)': False, 'contains(plane)': False, 'contains(hits)': False, 'contains(open)': False, 'contains(loathing)': False, 'contains(each)': True, 'contains(periodic)': False, 'contains(stops)': True, 'contains(puke)': False, 'contains(dashboard)': False, 'contains(whenever)': False, 'contains(muttering)': False, 'contains(rotten)': False, 'contains(turned)': False, 'contains(sloshed)': False, 'contains(viewpoint)': False, 'contains(recognizes)': False, 'contains(apple)': False, 'contains(hasn)': False, 'contains(fallen)': False, 'contains(tree)': False, 'contains(nosebleeds)': False, 'contains(snorting)': False, 'contains(coke)': False, 'contains(sabotages)': False, 'contains(personal)': False, 'contains(indifference)': False, 'contains(restrain)': False, 'contains(vindictive)': False, 'contains(temper)': False, 'contains(ain)': False, 'contains(pair)': False, 'contains(true)': False, 'contains(notes)': False, 'contains(unspoken)': False, 'contains(familial)': False, 'contains(empathy)': False, 'contains(note)': False, 'contains(repetitively)': False, 'contains(bitchy)': False, 'contains(screenwriters)': False, 'contains(kristin)': False, 'contains(amundsen)': False, 'contains(hans)': False, 'contains(petter)': False, 'contains(moland)': False, 'contains(fabricate)': False, 'contains(series)': True, 'contains(contrivances)': False, 'contains(propel)': False, 'contains(forward)': False, 'contains(roving)': False, 'contains(hooligans)': False, 'contains(drunks)': False, 'contains(nosy)': False, 'contains(flat)': False, 'contains(tires)': False, 'contains(figure)': False, 'contains(schematic)': False, 'contains(convenient)': False, 'contains(narrative)': False, 'contains(reach)': False, 'contains(unveil)': False, 'contains(dark)': False, 'contains(past)': False, 'contains(simplistic)': False, 'contains(devices)': False, 'contains(trivialize)': False, 'contains(conflict)': False, 'contains(mainstays)': False, 'contains(wannabe)': False, 'contains(exists)': False, 'contains(purely)': False, 'contains(sake)': False, 'contains(weak)': False, 'contains(unimaginative)': False, 'contains(casting)': False, 'contains(thwarts)': False, 'contains(pivotal)': False, 'contains(role)': False, 'contains(were)': False, 'contains(stronger)': False, 'contains(actress)': False, 'contains(perhaps)': False, 'contains(coast)': True, 'contains(performances)': False, 'contains(moody)': False, 'contains(haunting)': False, 'contains(cinematography)': False, 'contains(rendering)': False, 'contains(pastoral)': False, 'contains(ghost)': False, 'contains(reference)': False, 'contains(certain)': False, 'contains(superior)': False, 'contains(indie)': False, 'contains(intentional)': False, 'contains(busy)': False, 'contains(using)': False, 'contains(furrowed)': False, 'contains(brow)': False, 'contains(convey)': False, 'contains(twitch)': False, 'contains(insouciance)': False, 'contains(paying)': False, 'contains(attention)': False, 'contains(maybe)': False, 'contains(doing)': False, 'contains(reveal)': False, 'contains(worthwhile)': False, 'contains(earlier)': False, 'contains(released)': False, 'contains(2001)': False, 'contains(jonathan)': False, 'contains(nossiter)': False, 'contains(captivating)': False, 'contains(wonders)': False, 'contains(disturbed)': False, 'contains(parental)': False, 'contains(figures)': False, 'contains(bound)': False, 'contains(ceremonial)': False, 'contains(wedlock)': False, 'contains(differences)': False, 'contains(presented)': False, 'contains(significant)': False, 'contains(luminous)': False, 'contains(diva)': False, 'contains(preening)': False, 'contains(static)': False, 'contains(solid)': False, 'contains(performance)': False, 'contains(pathetic)': False, 'contains(drunk)': False, 'contains(emote)': False, 'contains(besides)': False, 'contains(catatonic)': False, 'contains(sorrow)': False, 'contains(genuine)': False, 'contains(ferocity)': False, 'contains(sexually)': False, 'contains(charged)': False, 'contains(frisson)': False, 'contains(during)': False, 'contains(understated)': False, 'contains(confrontations)': False, 'contains(suggest)': False, 'contains(gray)': False, 'contains(zone)': False, 'contains(complications)': False, 'contains(accompany)': False, 'contains(torn)': False, 'contains(romance)': False, 'contains(stifled)': False, 'contains(curiosity)': False, 'contains(thoroughly)': False, 'contains(explores)': False, 'contains(neurotic)': False, 'contains(territory)': False, 'contains(delving)': False, 'contains(americanization)': False, 'contains(greece)': False, 'contains(mysticism)': False, 'contains(illusion)': False, 'contains(deflect)': False, 'contains(pain)': False, 'contains(overloaded)': False, 'contains(willing)': False, 'contains(come)': False, 'contains(traditional)': False, 'contains(ambitious)': False, 'contains(sleepwalk)': False, 'contains(rhythms)': False, 'contains(timing)': False, 'contains(driven)': False, 'contains(stories)': False, 'contains(complexities)': False, 'contains(depressing)': False, 'contains(answer)': False, 'contains(lawrence)': False, 'contains(kasdan)': False, 'contains(trite)': False, 'contains(useful)': False, 'contains(grand)': False, 'contains(canyon)': False, 'contains(steve)': False, 'contains(martin)': False, 'contains(mogul)': False, 'contains(pronounces)': False, 'contains(riddles)': False, 'contains(answered)': False, 'contains(advice)': False, 'contains(heart)': False, 'contains(french)': False, 'contains(sees)': True, 'contains(parents)': False, 'contains(tim)': False, 'contains(roth)': False, 'contains(oops)': False, 'contains(vows)': False, 'contains(taught)': False, 'contains(musketeer)': False, 'contains(dude)': False, 'contains(used)': True, 'contains(fourteen)': False, 'contains(arrgh)': False, 'contains(swish)': False, 'contains(zzzzzzz)': False, 'contains(original)': False, 'contains(lacks)': False, 'contains(energy)': False, 'contains(next)': False, 'contains(hmmmm)': False, 'contains(justin)': False, 'contains(chambers)': False, 'contains(basically)': False, 'contains(uncharismatic)': False, 'contains(version)': False, 'contains(chris)': False, 'contains(o)': False, 'contains(donnell)': False, 'contains(range)': False, 'contains(mena)': False, 'contains(suvari)': False, 'contains(thora)': False, 'contains(birch)': False, 'contains(dungeons)': False, 'contains(dragons)': False, 'contains(miscast)': False, 'contains(deliveries)': False, 'contains(piss)': False, 'contains(poor)': False, 'contains(ms)': False, 'contains(fault)': False, 'contains(definitely)': False, 'contains(higher)': False, 'contains(semi)': False, 'contains(saving)': False, 'contains(grace)': False, 'contains(wise)': False, 'contains(irrepressible)': False, 'contains(once)': True, 'contains(thousand)': False, 'contains(god)': False, 'contains(beg)': False, 'contains(agent)': False, 'contains(marketplace)': False, 'contains(modern)': False, 'contains(day)': True, 'contains(roles)': False, 'contains(romantic)': False, 'contains(gunk)': False, 'contains(alright)': False, 'contains(yeah)': False, 'contains(yikes)': False, 'contains(notches)': False, 'contains(fellas)': False, 'contains(blares)': False, 'contains(ear)': False, 'contains(accentuate)': False, 'contains(annoy)': False, 'contains(important)': False, 'contains(behind)': False, 'contains(recognize)': False, 'contains(epic)': False, 'contains(fluffy)': False, 'contains(rehashed)': False, 'contains(cake)': False, 'contains(created)': False, 'contains(shrewd)': False, 'contains(advantage)': False, 'contains(kung)': True, 'contains(fu)': True, 'contains(phenomenon)': False, 'contains(test)': False, 'contains(dudes)': False, 'contains(keep)': False, 'contains(reading)': False, 'contains(editing)': False, 'contains(shoddy)': False, 'contains(banal)': False, 'contains(stilted)': False, 'contains(plentiful)': False, 'contains(top)': True, 'contains(horse)': False, 'contains(carriage)': False, 'contains(stand)': False, 'contains(opponent)': False, 'contains(scampering)': False, 'contains(cut)': False, 'contains(mouseketeer)': False, 'contains(rope)': False, 'contains(tower)': False, 'contains(jumping)': False, 'contains(chords)': False, 'contains(hanging)': False, 'contains(says)': False, 'contains(14)': False, 'contains(shirt)': False, 'contains(strayed)': False, 'contains(championing)': False, 'contains(fun)': True, 'contains(stretches)': False, 'contains(atrocious)': False, 'contains(lake)': False, 'contains(reminded)': False, 'contains(school)': False, 'contains(cringe)': False, 'contains(musketeers)': False, 'contains(fat)': False, 'contains(raison)': False, 'contains(etre)': False, 'contains(numbers)': False, 'contains(hoping)': False, 'contains(packed)': False, 'contains(stuntwork)': False, 'contains(promoted)': False, 'contains(trailer)': False, 'contains(major)': False, 'contains(swashbuckling)': False, 'contains(beginning)': False, 'contains(finishes)': False, 'contains(juggling)': False, 'contains(ladders)': False, 'contains(ladder)': True, 'contains(definite)': False, 'contains(keeper)': False, 'contains(regurgitated)': False, 'contains(crap)': False, 'contains(tell)': False, 'contains(deneuve)': False, 'contains(placed)': False, 'contains(hullo)': False, 'contains(barely)': False, 'contains(ugh)': False, 'contains(small)': False, 'contains(annoyed)': False, 'contains(trash)': False, 'contains(gang)': False, 'contains(vow)': False, 'contains(stay)': False, 'contains(thank)': False, 'contains(outlaws)': False, 'contains(5)': False, 'contains(crouching)': False, 'contains(tiger)': False, 'contains(hidden)': False, 'contains(matrix)': False, 'contains(replacement)': False, 'contains(killers)': False, 'contains(6)': False, 'contains(romeo)': False, 'contains(die)': False, 'contains(shanghai)': False, 'contains(noon)': False, 'contains(remembered)': False, 'contains(dr)': False, 'contains(hannibal)': False, 'contains(lecter)': False, 'contains(michael)': False, 'contains(mann)': False, 'contains(forensics)': False, 'contains(thriller)': False, 'contains(manhunter)': False, 'contains(scottish)': False, 'contains(brian)': False, 'contains(cox)': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKSkDVnyxU_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-EYCswaRxXbE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f15ca3e-e9bb-4cb6-a7d2-afe4e38f9d35"
      },
      "cell_type": "code",
      "source": [
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xl8Jx22dxbxU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c5f40365-1113-4357-bea3-bbceba07d47c"
      },
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "     contains(stretched) = True              neg : pos    =      9.6 : 1.0\n",
            " contains(unimaginative) = True              neg : pos    =      7.7 : 1.0\n",
            "    contains(schumacher) = True              neg : pos    =      7.4 : 1.0\n",
            "        contains(sexist) = True              neg : pos    =      7.0 : 1.0\n",
            "     contains(atrocious) = True              neg : pos    =      6.6 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XYLUzdCUxl81",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ea41de2d-0730-4bb8-d76f-ec305dbe5b97"
      },
      "cell_type": "code",
      "source": [
        "  >>> import nltk\n",
        "  >>> nltk.download('brown')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "pnYPwhCoxdlu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> from nltk.corpus import brown\n",
        ">>> suffix_fdist = nltk.FreqDist()\n",
        ">>> for word in brown.words():\n",
        "...     word = word.lower()\n",
        "...     suffix_fdist[word[-1:]] += 1\n",
        "...     suffix_fdist[word[-2:]] += 1\n",
        "...     suffix_fdist[word[-3:]] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "os37WznPxirI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e8033c3f-e60d-4503-fea1-f7a593487e2e"
      },
      "cell_type": "code",
      "source": [
        ">>> common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
        ">>> print(common_suffixes)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qecFbOH8xpCv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> def pos_features(word):\n",
        "...     features = {}\n",
        "...     for suffix in common_suffixes:\n",
        "...         features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
        "...     return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "baVHxPAoxsrk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> tagged_words = brown.tagged_words(categories='news')\n",
        ">>> featuresets = [(pos_features(n), g) for (n,g) in tagged_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5e_OowD-xuZu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> size = int(len(featuresets) * 0.1)\n",
        ">>> train_set, test_set = featuresets[size:], featuresets[:size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t5wBefPRxwEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba9149ac-b44b-4d77-f5a8-d79054a80430"
      },
      "cell_type": "code",
      "source": [
        ">>> classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
        ">>> nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6270512182993535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "Kwy-JnfSxxgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fac802bc-c2e7-45f2-ac7e-bb0000968660"
      },
      "cell_type": "code",
      "source": [
        ">>> classifier.classify(pos_features('cats'))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NNS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "gEVSwUjzxzPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e5d638fc-2f3b-4305-9a3e-ca2683d76865"
      },
      "cell_type": "code",
      "source": [
        ">>> print(classifier.pseudocode(depth=4))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "if endswith(the) == False: \n",
            "  if endswith(,) == False: \n",
            "    if endswith(s) == False: \n",
            "      if endswith(.) == False: return '.'\n",
            "      if endswith(.) == True: return '.'\n",
            "    if endswith(s) == True: \n",
            "      if endswith(is) == False: return 'PP$'\n",
            "      if endswith(is) == True: return 'BEZ'\n",
            "  if endswith(,) == True: return ','\n",
            "if endswith(the) == True: return 'AT'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0aV391MCx1ZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pos_features(sentence, i): \n",
        "    features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                \"suffix(2)\": sentence[i][-2:],\n",
        "                \"suffix(3)\": sentence[i][-3:]}\n",
        "    if i == 0:\n",
        "        features[\"prev-word\"] = \"<START>\"\n",
        "    else:\n",
        "        features[\"prev-word\"] = sentence[i-1]\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B0z0sfzcx55y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a504e80b-4329-4633-ccd7-5a909130e9c4"
      },
      "cell_type": "code",
      "source": [
        "pos_features(brown.sents()[0], 8)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prev-word': 'an', 'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "rtTx660tx7pM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5a49816-f1c2-4f1c-f45d-eed49863c301"
      },
      "cell_type": "code",
      "source": [
        ">>> tagged_sents = brown.tagged_sents(categories='news')\n",
        ">>> featuresets = []\n",
        ">>> for tagged_sent in tagged_sents:\n",
        "...     untagged_sent = nltk.tag.untag(tagged_sent)\n",
        "...     for i, (word, tag) in enumerate(tagged_sent):\n",
        "...         featuresets.append( (pos_features(untagged_sent, i), tag) )\n",
        "\n",
        ">>> size = int(len(featuresets) * 0.1)\n",
        ">>> train_set, test_set = featuresets[size:], featuresets[:size]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        ">>> nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7891596220785678"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "UQdJkTkUx-VB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " def pos_features(sentence, i, history): \n",
        "     features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                 \"suffix(2)\": sentence[i][-2:],\n",
        "                 \"suffix(3)\": sentence[i][-3:]}\n",
        "     if i == 0:\n",
        "         features[\"prev-word\"] = \"<START>\"\n",
        "         features[\"prev-tag\"] = \"<START>\"\n",
        "     else:\n",
        "         features[\"prev-word\"] = sentence[i-1]\n",
        "         features[\"prev-tag\"] = history[i-1]\n",
        "     return features\n",
        "\n",
        "class ConsecutivePosTagger(nltk.TaggerI):\n",
        "\n",
        "    def __init__(self, train_sents):\n",
        "        train_set = []\n",
        "        for tagged_sent in train_sents:\n",
        "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
        "            history = []\n",
        "            for i, (word, tag) in enumerate(tagged_sent):\n",
        "                featureset = pos_features(untagged_sent, i, history)\n",
        "                train_set.append( (featureset, tag) )\n",
        "                history.append(tag)\n",
        "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "    def tag(self, sentence):\n",
        "        history = []\n",
        "        for i, word in enumerate(sentence):\n",
        "            featureset = pos_features(sentence, i, history)\n",
        "            tag = self.classifier.classify(featureset)\n",
        "            history.append(tag)\n",
        "        return zip(sentence, history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gziNY4koyC_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b393d40-9e4b-4fd9-85f6-b5d705f6f84c"
      },
      "cell_type": "code",
      "source": [
        ">>> tagged_sents = brown.tagged_sents(categories='news')\n",
        ">>> size = int(len(tagged_sents) * 0.1)\n",
        ">>> train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
        ">>> tagger = ConsecutivePosTagger(train_sents)\n",
        ">>> print(tagger.evaluate(test_sents))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7980528511821975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vVN_NMhL4NTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "489c0b6a-2d56-4b4f-cd99-8908bc6cda37"
      },
      "cell_type": "code",
      "source": [
        "  >>> import nltk\n",
        "  >>> nltk.download('treebank')\n",
        "  >>> import nltk\n",
        "  >>> nltk.download('punkt')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "6Z4kL-aRyEz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> sents = nltk.corpus.treebank_raw.sents()\n",
        ">>> tokens = []\n",
        ">>> boundaries = set()\n",
        ">>> offset = 0\n",
        ">>> for sent in sents:\n",
        "...     tokens.extend(sent)\n",
        "...     offset += len(sent)\n",
        "...     boundaries.add(offset-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSEm8vxhyHe2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> def punct_features(tokens, i):\n",
        "...     return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
        "...             'prev-word': tokens[i-1].lower(),\n",
        "...             'punct': tokens[i],\n",
        "...             'prev-word-is-one-char': len(tokens[i-1]) == 1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkbMny1iyI5x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
        "...                for i in range(1, len(tokens)-1)\n",
        "...                if tokens[i] in '.?!']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ma5WUf8ByKcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01cb12f9-e5f3-4cef-cca9-e213a88d0d69"
      },
      "cell_type": "code",
      "source": [
        ">>> size = int(len(featuresets) * 0.1)\n",
        ">>> train_set, test_set = featuresets[size:], featuresets[:size]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.936026936026936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "zMwbK6EjyLzF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def segment_sentences(words):\n",
        "    start = 0\n",
        "    sents = []\n",
        "    for i, word in enumerate(words):\n",
        "        if word in '.?!' and classifier.classify(punct_features(words, i)) == True:\n",
        "            sents.append(words[start:i+1])\n",
        "            start = i+1\n",
        "    if start < len(words):\n",
        "        sents.append(words[start:])\n",
        "    return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P1_Hhzj44ZuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "427b83e8-2c78-4f47-cdd3-9a1543e7a938"
      },
      "cell_type": "code",
      "source": [
        "  >>> import nltk\n",
        "  >>> nltk.download('nps_chat')\n",
        "  "
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "P4wr33kGyNWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u8BsWIexyO7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> def dialogue_act_features(post):\n",
        "...     features = {}\n",
        "...     for word in nltk.word_tokenize(post):\n",
        "...         features['contains({})'.format(word.lower())] = True\n",
        "...     return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLrGmQkEyQSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac32bd31-f2d1-43f3-a3fe-896bbe081bb6"
      },
      "cell_type": "code",
      "source": [
        ">>> featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
        "...                for post in posts]\n",
        ">>> size = int(len(featuresets) * 0.1)\n",
        ">>> train_set, test_set = featuresets[size:], featuresets[:size]\n",
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        ">>> print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ohDjRiaTyRzC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rte_features(rtepair):\n",
        "    extractor = nltk.RTEFeatureExtractor(rtepair)\n",
        "    features = {}\n",
        "    features['word_overlap'] = len(extractor.overlap('word'))\n",
        "    features['word_hyp_extra'] = len(extractor.hyp_extra('word'))\n",
        "    features['ne_overlap'] = len(extractor.overlap('ne'))\n",
        "    features['ne_hyp_extra'] = len(extractor.hyp_extra('ne'))\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OFRzfC-R4hwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a8e7afb3-9d55-4405-b1d1-818a5ec80115"
      },
      "cell_type": "code",
      "source": [
        "  >>> import nltk\n",
        "  >>> nltk.download('rte')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]   Package rte is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "aTizt5RvyT4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "35eceff7-ac8b-44e6-ee16-7baa60abf963"
      },
      "cell_type": "code",
      "source": [
        ">>> rtepair = nltk.corpus.rte.pairs(['rte3_dev.xml'])[33]\n",
        ">>> extractor = nltk.RTEFeatureExtractor(rtepair)\n",
        ">>> print(extractor.text_words)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Co', 'SCO', 'was', 'Soviet', 'Shanghai', 'Asia', 'association', 'binds', 'fledgling', 'representing', 'at', 'China', 'four', 'meeting', 'fight', 'Davudi', 'operation', 'republics', 'together', 'terrorism.', 'that', 'central', 'Iran', 'former', 'Russia', 'Parviz', 'Organisation'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gkg7uL-nyVrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac0a3386-4481-420a-feee-0e468e345022"
      },
      "cell_type": "code",
      "source": [
        ">>> print(extractor.hyp_words)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'China', 'SCO.', 'member'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tfrKbCvdyXSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93824993-a614-428b-ad6b-d6fa195d4725"
      },
      "cell_type": "code",
      "source": [
        ">>> print(extractor.overlap('word'))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "set()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GQLinQPRyYnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55b53530-8dfe-4418-fcbd-7f2e9306a3e9"
      },
      "cell_type": "code",
      "source": [
        ">>> print(extractor.overlap('ne'))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'China'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A4uduCx9yZxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe2b667f-3a8d-47d6-fcea-5e3a661dfbb1"
      },
      "cell_type": "code",
      "source": [
        ">>> print(extractor.hyp_extra('word'))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'member'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LPnMEcwRybWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> import random\n",
        ">>> from nltk.corpus import brown\n",
        ">>> tagged_sents = list(brown.tagged_sents(categories='news'))\n",
        ">>> random.shuffle(tagged_sents)\n",
        ">>> size = int(len(tagged_sents) * 0.1)\n",
        ">>> train_set, test_set = tagged_sents[size:], tagged_sents[:size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pt8v0UPGydc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> file_ids = brown.fileids(categories='news')\n",
        ">>> size = int(len(file_ids) * 0.1)\n",
        ">>> train_set = brown.tagged_sents(file_ids[size:])\n",
        ">>> test_set = brown.tagged_sents(file_ids[:size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wb9ea2HTyexo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ">>> train_set = brown.tagged_sents(categories='news')\n",
        ">>> test_set = brown.tagged_sents(categories='fiction')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N78gDxRfyf_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "8f85b57b-6da5-4f77-89aa-521d8de146d6"
      },
      "cell_type": "code",
      "source": [
        ">>> classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
        ">>> print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(classifier, test_set))) "
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-0c24f7f4fe5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: {:4.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/classify/naivebayes.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Count up how many times each feature value occurred, given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# the label and featurename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mlabel_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fOrMeScSyhg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4b4e418b-6288-4b86-d18b-7e9b1ff4d03c"
      },
      "cell_type": "code",
      "source": [
        ">>> def tag_list(tagged_sents):\n",
        "...     return [tag for sent in tagged_sents for (word, tag) in sent]\n",
        ">>> def apply_tagger(tagger, corpus):\n",
        "...     return [tagger.tag(nltk.tag.untag(sent)) for sent in corpus]\n",
        ">>> gold = tag_list(brown.tagged_sents(categories='editorial'))\n",
        ">>> test = tag_list(apply_tagger(t2, brown.tagged_sents(categories='editorial')))\n",
        ">>> cm = nltk.ConfusionMatrix(gold, test)\n",
        ">>> print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-2ecf7e4f93d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'editorial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'editorial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort_by_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_percents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 't2' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "A3Iv8xddys5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\t\n",
        "import math\n",
        "def entropy(labels):\n",
        "    freqdist = nltk.FreqDist(labels)\n",
        "    probs = [freqdist.freq(l) for l in freqdist]\n",
        "    return -sum(p * math.log(p,2) for p in probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aus9lwZ3y0_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63d0bb15-0fee-4daa-c0cd-b4c8875bc9c0"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['male', 'male', 'male', 'male'])) "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qs7dSFGay2kP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65828c7b-57a1-4083-bfb1-ab96529e7957"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['male', 'female', 'male', 'male']))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8112781244591328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zbn-cmBky7Vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fcd961c-8c13-40ab-db46-bd6b22d966e0"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['female', 'male', 'female', 'male']))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zTBaQeHHy9a5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97c24b3e-8659-4108-fadf-194720ce0024"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['female', 'female', 'male', 'female']))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8112781244591328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xZ-yC59Cy-zu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86ac577b-9bb8-4997-aff6-0246c6526e15"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['female', 'female', 'female', 'female'])) "
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P4j7Gt1JzAN9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}